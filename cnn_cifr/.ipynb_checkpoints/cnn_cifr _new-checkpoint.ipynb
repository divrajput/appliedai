{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lJSCFO_ZAqSL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AP0NPq-J67I2"
   },
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOg-v8fFAvc5",
    "outputId": "c5b4e73d-4cc0-4a6a-a3e9-65bf1568182b"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "num_classes= 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rxbkPro6_iF"
   },
   "source": [
    "## FUNCTION TO NORMALIZE IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oAyl9flsAycp"
   },
   "outputs": [],
   "source": [
    "def normalize_data(X):\n",
    "    return (X - np.mean(X))/np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bEbo6byYA23g"
   },
   "outputs": [],
   "source": [
    "X_train = normalize_data(X_train.astype(\"float32\"))\n",
    "X_test = normalize_data(X_test.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Otwrdp4TA5LZ"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "num_classes = 10\n",
    "epochs =300\n",
    "l = 12\n",
    "num_filter = 12\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hL4teEi7GQY"
   },
   "source": [
    "## DENSENET MODEL WITHOUT BOTTLENECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "F3zydph0A7MG"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Blosck\n",
    "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bsTg4thSA9W5"
   },
   "outputs": [],
   "source": [
    "def dense_model(input_shape = (32,32,3), n_classes = 10):\n",
    "    X_input = Input(shape=(img_height, img_width, channel))\n",
    "    First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(X_input)\n",
    "    \n",
    "    First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "    First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "    Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "    Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "    Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "    Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "    Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "    output = output_layer(Last_Block)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vO0GvSoKA_hd",
    "outputId": "e9ab5551-e34c-4397-d8d8-17e8b13c10b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 12)   324         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 12)   48          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 12)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 6)    648         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 6)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 18)   0           conv2d[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 18)   72          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 18)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 6)    972         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 6)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 24)   0           concatenate[0][0]                \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 24)   96          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 24)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 6)    1296        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 6)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 30)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 30)   120         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 30)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 6)    1620        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 6)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 36)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 36)   144         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 36)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 6)    1944        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 6)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 42)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 42)   168         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 42)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 6)    2268        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 6)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 48)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 6)    2592        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 6)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 54)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 54)   216         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 54)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 6)    2916        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 6)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 60)   0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 60)   240         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 60)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 6)    3240        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 6)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 66)   0           concatenate_7[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 66)   264         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 66)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 6)    3564        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 6)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 72)   0           concatenate_8[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 72)   288         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 72)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 6)    3888        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 6)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 78)   0           concatenate_9[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 78)   312         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 78)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 6)    4212        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 6)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 84)   0           concatenate_10[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 84)   336         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 84)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 6)    504         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 6)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 6)    0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 6)    24          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 6)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 6)    324         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 6)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 12)   0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 12)   48          concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 12)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 6)    648         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 6)    0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 18)   0           concatenate_12[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 18)   72          concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 18)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 6)    972         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 6)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 24)   0           concatenate_13[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 24)   96          concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 24)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 6)    1296        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 6)    0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 30)   0           concatenate_14[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 30)   120         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 30)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 6)    1620        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 6)    0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 36)   0           concatenate_15[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 36)   144         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 36)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 6)    1944        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 6)    0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 42)   0           concatenate_16[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 42)   168         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 42)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 6)    2268        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 6)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 48)   0           concatenate_17[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   192         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 6)    2592        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 6)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 54)   0           concatenate_18[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 54)   216         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 54)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 6)    2916        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 6)    0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 60)   0           concatenate_19[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 60)   240         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 60)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 6)    3240        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 6)    0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 66)   0           concatenate_20[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 66)   264         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 66)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 6)    3564        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 6)    0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 72)   0           concatenate_21[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 72)   288         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 72)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 6)    3888        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 6)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 78)   0           concatenate_22[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 78)   312         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 78)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 6)    468         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 6)    0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 6)      0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 6)      24          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 6)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 6)      324         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 6)      0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 12)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 12)     48          concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 12)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 6)      648         activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 8, 8, 6)      0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 18)     0           concatenate_24[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 18)     72          concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 18)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 6)      972         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 8, 8, 6)      0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 24)     0           concatenate_25[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 24)     96          concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 24)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 6)      1296        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 8, 8, 6)      0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 30)     0           concatenate_26[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 30)     120         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 30)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 6)      1620        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 8, 8, 6)      0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 36)     0           concatenate_27[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 36)     144         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 36)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 6)      1944        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 8, 8, 6)      0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 42)     0           concatenate_28[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 42)     168         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 42)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 6)      2268        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 8, 8, 6)      0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 48)     0           concatenate_29[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 48)     192         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 48)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 6)      2592        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 8, 8, 6)      0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 54)     0           concatenate_30[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 54)     216         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 54)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 6)      2916        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 8, 8, 6)      0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 60)     0           concatenate_31[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 60)     240         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 60)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 6)      3240        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 8, 8, 6)      0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 66)     0           concatenate_32[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 66)     264         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 66)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 6)      3564        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 8, 8, 6)      0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 72)     0           concatenate_33[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 72)     288         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 72)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 6)      3888        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 8, 8, 6)      0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 78)     0           concatenate_34[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 78)     312         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 78)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 6)      468         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 8, 8, 6)      0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 6)      0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 4, 4, 6)      24          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 6)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 4, 4, 6)      324         activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 4, 4, 6)      0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 12)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 12)     48          concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 12)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 4, 4, 6)      648         activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 4, 4, 6)      0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 18)     0           concatenate_36[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 4, 4, 18)     72          concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 18)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 4, 4, 6)      972         activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 4, 4, 6)      0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 24)     0           concatenate_37[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 4, 24)     96          concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 24)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 4, 4, 6)      1296        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 4, 4, 6)      0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 30)     0           concatenate_38[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 4, 30)     120         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 30)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 4, 4, 6)      1620        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 4, 4, 6)      0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 36)     0           concatenate_39[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 36)     144         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 36)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 4, 4, 6)      1944        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 4, 4, 6)      0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 42)     0           concatenate_40[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 42)     168         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 42)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 4, 6)      2268        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 4, 4, 6)      0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 48)     0           concatenate_41[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 48)     192         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 48)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 6)      2592        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 4, 4, 6)      0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 54)     0           concatenate_42[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 54)     216         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 54)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 6)      2916        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 4, 4, 6)      0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 60)     0           concatenate_43[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 60)     240         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 60)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 6)      3240        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 4, 4, 6)      0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 66)     0           concatenate_44[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 66)     264         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 66)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 6)      3564        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 4, 4, 6)      0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 72)     0           concatenate_45[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 72)     288         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 72)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 6)      3888        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 4, 4, 6)      0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 78)     0           concatenate_46[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 78)     312         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 78)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 78)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 312)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           3130        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 118,918\n",
      "Trainable params: 114,394\n",
      "Non-trainable params: 4,524\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = dense_model(input_shape = (32,32,3), n_classes = 10)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BaL2QDV9r9mw",
    "outputId": "14708afb-c3a9-41ff-8980-d364eca55772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n"
     ]
    }
   ],
   "source": [
    "print(len(model_1.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "c8sG5mBmsC9m"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "VhRDaAkysobu",
    "outputId": "3c825d85-ccfb-458e-dbc3-a024806de029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 1.6340 - accuracy: 0.3941 - val_loss: 1.7718 - val_accuracy: 0.4311\n",
      "Epoch 2/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 1.2819 - accuracy: 0.5333 - val_loss: 1.1819 - val_accuracy: 0.5806\n",
      "Epoch 3/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 1.1291 - accuracy: 0.5932 - val_loss: 1.2765 - val_accuracy: 0.5776\n",
      "Epoch 4/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 1.0408 - accuracy: 0.6282 - val_loss: 1.0265 - val_accuracy: 0.6501\n",
      "Epoch 5/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.9840 - accuracy: 0.6473 - val_loss: 1.3691 - val_accuracy: 0.5865\n",
      "Epoch 6/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.9390 - accuracy: 0.6633 - val_loss: 1.2947 - val_accuracy: 0.6004\n",
      "Epoch 7/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.8996 - accuracy: 0.6781 - val_loss: 0.9223 - val_accuracy: 0.6833\n",
      "Epoch 8/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.8633 - accuracy: 0.6937 - val_loss: 0.8341 - val_accuracy: 0.715436 \n",
      "Epoch 9/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.8371 - accuracy: 0.7039 - val_loss: 1.0094 - val_accuracy: 0.6719\n",
      "Epoch 10/300\n",
      "3125/3125 [==============================] - 149s 48ms/step - loss: 0.8092 - accuracy: 0.7141 - val_loss: 0.9770 - val_accuracy: 0.6797\n",
      "Epoch 11/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.7867 - accuracy: 0.7210 - val_loss: 0.7559 - val_accuracy: 0.7346\n",
      "Epoch 12/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.7652 - accuracy: 0.7304 - val_loss: 0.8536 - val_accuracy: 0.7157\n",
      "Epoch 13/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.7458 - accuracy: 0.7374 - val_loss: 1.0022 - val_accuracy: 0.6779\n",
      "Epoch 14/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.7338 - accuracy: 0.7389 - val_loss: 0.8828 - val_accuracy: 0.7154\n",
      "Epoch 15/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.7127 - accuracy: 0.7470 - val_loss: 0.8762 - val_accuracy: 0.7177\n",
      "Epoch 16/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.7018 - accuracy: 0.7520 - val_loss: 0.7839 - val_accuracy: 0.7381\n",
      "Epoch 17/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.6894 - accuracy: 0.7586 - val_loss: 0.7589 - val_accuracy: 0.7452\n",
      "Epoch 18/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.6749 - accuracy: 0.7607 - val_loss: 0.7647 - val_accuracy: 0.7490\n",
      "Epoch 19/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.6658 - accuracy: 0.7647 - val_loss: 0.7220 - val_accuracy: 0.7563\n",
      "Epoch 20/300\n",
      "3125/3125 [==============================] - 142s 45ms/step - loss: 0.6608 - accuracy: 0.7683 - val_loss: 0.6659 - val_accuracy: 0.7727\n",
      "Epoch 21/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.6418 - accuracy: 0.7732 - val_loss: 0.6955 - val_accuracy: 0.7706\n",
      "Epoch 22/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.6397 - accuracy: 0.7754 - val_loss: 0.7018 - val_accuracy: 0.7670\n",
      "Epoch 23/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.6318 - accuracy: 0.7788 - val_loss: 0.8836 - val_accuracy: 0.7220\n",
      "Epoch 24/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.6211 - accuracy: 0.7822 - val_loss: 0.7320 - val_accuracy: 0.7609\n",
      "Epoch 25/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.6152 - accuracy: 0.7835 - val_loss: 0.6626 - val_accuracy: 0.7794\n",
      "Epoch 26/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.6081 - accuracy: 0.7858 - val_loss: 0.6746 - val_accuracy: 0.7805\n",
      "Epoch 27/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.6012 - accuracy: 0.7897 - val_loss: 0.6445 - val_accuracy: 0.7897\n",
      "Epoch 28/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.5998 - accuracy: 0.7888 - val_loss: 0.7756 - val_accuracy: 0.7521\n",
      "Epoch 29/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.5924 - accuracy: 0.7931 - val_loss: 0.6884 - val_accuracy: 0.7773\n",
      "Epoch 30/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.5856 - accuracy: 0.7921 - val_loss: 0.6415 - val_accuracy: 0.7855\n",
      "Epoch 31/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.5771 - accuracy: 0.7985 - val_loss: 0.7738 - val_accuracy: 0.7524\n",
      "Epoch 32/300\n",
      "3125/3125 [==============================] - 142s 45ms/step - loss: 0.5724 - accuracy: 0.7986 - val_loss: 0.6547 - val_accuracy: 0.7865\n",
      "Epoch 33/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.5734 - accuracy: 0.7964 - val_loss: 0.7032 - val_accuracy: 0.7723\n",
      "Epoch 34/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.5681 - accuracy: 0.8018 - val_loss: 0.6588 - val_accuracy: 0.7842\n",
      "Epoch 35/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.5593 - accuracy: 0.8030 - val_loss: 0.5814 - val_accuracy: 0.8084\n",
      "Epoch 36/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.5569 - accuracy: 0.8051 - val_loss: 0.6222 - val_accuracy: 0.7997\n",
      "Epoch 37/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.5514 - accuracy: 0.8055 - val_loss: 0.6484 - val_accuracy: 0.7857\n",
      "Epoch 38/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.5479 - accuracy: 0.8101 - val_loss: 0.6219 - val_accuracy: 0.7932\n",
      "Epoch 39/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.5449 - accuracy: 0.8097 - val_loss: 0.5954 - val_accuracy: 0.8061\n",
      "Epoch 40/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.5411 - accuracy: 0.8123 - val_loss: 0.6289 - val_accuracy: 0.7960\n",
      "Epoch 41/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.5369 - accuracy: 0.8119 - val_loss: 0.5888 - val_accuracy: 0.8086\n",
      "Epoch 42/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.5333 - accuracy: 0.8139 - val_loss: 0.6196 - val_accuracy: 0.8015\n",
      "Epoch 43/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.5342 - accuracy: 0.8137 - val_loss: 0.6127 - val_accuracy: 0.8046\n",
      "Epoch 44/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.5278 - accuracy: 0.8147 - val_loss: 0.6533 - val_accuracy: 0.7906\n",
      "Epoch 45/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.5255 - accuracy: 0.8153 - val_loss: 0.6722 - val_accuracy: 0.7880\n",
      "Epoch 46/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.5218 - accuracy: 0.8155 - val_loss: 0.6186 - val_accuracy: 0.7976\n",
      "Epoch 47/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.5216 - accuracy: 0.8173 - val_loss: 0.5938 - val_accuracy: 0.8075\n",
      "Epoch 48/300\n",
      "3125/3125 [==============================] - 141s 45ms/step - loss: 0.5143 - accuracy: 0.8184 - val_loss: 0.6211 - val_accuracy: 0.7994\n",
      "Epoch 49/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.5153 - accuracy: 0.8190 - val_loss: 0.6926 - val_accuracy: 0.7801\n",
      "Epoch 50/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.5119 - accuracy: 0.8203 - val_loss: 0.6817 - val_accuracy: 0.7839\n",
      "Epoch 51/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.5084 - accuracy: 0.8210 - val_loss: 0.6005 - val_accuracy: 0.8064\n",
      "Epoch 52/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.5067 - accuracy: 0.8218 - val_loss: 0.6002 - val_accuracy: 0.8052\n",
      "Epoch 53/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.5037 - accuracy: 0.8248 - val_loss: 0.6193 - val_accuracy: 0.8027\n",
      "Epoch 54/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.5034 - accuracy: 0.8234 - val_loss: 0.6238 - val_accuracy: 0.7979\n",
      "Epoch 55/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.4968 - accuracy: 0.8235 - val_loss: 0.5623 - val_accuracy: 0.8196\n",
      "Epoch 56/300\n",
      "3125/3125 [==============================] - 141s 45ms/step - loss: 0.5006 - accuracy: 0.8243 - val_loss: 0.5939 - val_accuracy: 0.8094\n",
      "Epoch 57/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.4957 - accuracy: 0.8271 - val_loss: 0.5740 - val_accuracy: 0.8169\n",
      "Epoch 58/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4938 - accuracy: 0.8248 - val_loss: 0.5950 - val_accuracy: 0.8067\n",
      "Epoch 59/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4887 - accuracy: 0.8280 - val_loss: 0.5930 - val_accuracy: 0.8066\n",
      "Epoch 60/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.4854 - accuracy: 0.8309 - val_loss: 0.5584 - val_accuracy: 0.8190\n",
      "Epoch 61/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.4874 - accuracy: 0.8298 - val_loss: 0.5945 - val_accuracy: 0.8081\n",
      "Epoch 62/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4843 - accuracy: 0.8289 - val_loss: 0.6605 - val_accuracy: 0.7948\n",
      "Epoch 63/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.4822 - accuracy: 0.8304 - val_loss: 0.5883 - val_accuracy: 0.8123\n",
      "Epoch 64/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.4764 - accuracy: 0.8329 - val_loss: 0.5961 - val_accuracy: 0.8109\n",
      "Epoch 65/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4803 - accuracy: 0.8314 - val_loss: 0.6790 - val_accuracy: 0.7858\n",
      "Epoch 66/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4752 - accuracy: 0.8326 - val_loss: 0.5598 - val_accuracy: 0.8217\n",
      "Epoch 67/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4724 - accuracy: 0.8353 - val_loss: 0.5725 - val_accuracy: 0.8145\n",
      "Epoch 68/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.4753 - accuracy: 0.8330 - val_loss: 0.5245 - val_accuracy: 0.8331\n",
      "Epoch 69/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.4686 - accuracy: 0.8354 - val_loss: 0.5255 - val_accuracy: 0.8307\n",
      "Epoch 70/300\n",
      "3125/3125 [==============================] - 143s 46ms/step - loss: 0.4708 - accuracy: 0.8372 - val_loss: 0.5723 - val_accuracy: 0.8170\n",
      "Epoch 71/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4697 - accuracy: 0.8350 - val_loss: 0.5404 - val_accuracy: 0.8264\n",
      "Epoch 72/300\n",
      "3125/3125 [==============================] - 141s 45ms/step - loss: 0.4658 - accuracy: 0.8359 - val_loss: 0.5949 - val_accuracy: 0.8140\n",
      "Epoch 73/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.4647 - accuracy: 0.8382 - val_loss: 0.5763 - val_accuracy: 0.8172\n",
      "Epoch 74/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4623 - accuracy: 0.8369 - val_loss: 0.5818 - val_accuracy: 0.8140\n",
      "Epoch 75/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4609 - accuracy: 0.8393 - val_loss: 0.5745 - val_accuracy: 0.8190\n",
      "Epoch 76/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4642 - accuracy: 0.8371 - val_loss: 0.5265 - val_accuracy: 0.8271\n",
      "Epoch 77/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.4581 - accuracy: 0.8410 - val_loss: 0.5262 - val_accuracy: 0.8304\n",
      "Epoch 78/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.4572 - accuracy: 0.8393 - val_loss: 0.5500 - val_accuracy: 0.8232\n",
      "Epoch 79/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.4580 - accuracy: 0.8394 - val_loss: 0.5395 - val_accuracy: 0.8295\n",
      "Epoch 80/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.4580 - accuracy: 0.8391 - val_loss: 0.5813 - val_accuracy: 0.8130\n",
      "Epoch 81/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4557 - accuracy: 0.8404 - val_loss: 0.5190 - val_accuracy: 0.8340\n",
      "Epoch 82/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4552 - accuracy: 0.8400 - val_loss: 0.5753 - val_accuracy: 0.8184\n",
      "Epoch 83/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4480 - accuracy: 0.8427 - val_loss: 0.5572 - val_accuracy: 0.8221\n",
      "Epoch 84/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4536 - accuracy: 0.8408 - val_loss: 0.5829 - val_accuracy: 0.8153\n",
      "Epoch 85/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4515 - accuracy: 0.8423 - val_loss: 0.6539 - val_accuracy: 0.7973\n",
      "Epoch 86/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4494 - accuracy: 0.8427 - val_loss: 0.5563 - val_accuracy: 0.8208\n",
      "Epoch 87/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4439 - accuracy: 0.8418 - val_loss: 0.6086 - val_accuracy: 0.8062\n",
      "Epoch 88/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4516 - accuracy: 0.8414 - val_loss: 0.5255 - val_accuracy: 0.8293\n",
      "Epoch 89/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.4432 - accuracy: 0.8439 - val_loss: 0.5412 - val_accuracy: 0.8263\n",
      "Epoch 90/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4462 - accuracy: 0.8430 - val_loss: 0.5906 - val_accuracy: 0.8141\n",
      "Epoch 91/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4387 - accuracy: 0.8464 - val_loss: 0.5252 - val_accuracy: 0.8318\n",
      "Epoch 92/300\n",
      "3125/3125 [==============================] - 142s 45ms/step - loss: 0.4414 - accuracy: 0.8452 - val_loss: 0.5137 - val_accuracy: 0.8362\n",
      "Epoch 93/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4405 - accuracy: 0.8463 - val_loss: 0.5843 - val_accuracy: 0.8149\n",
      "Epoch 94/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4373 - accuracy: 0.8469 - val_loss: 0.5277 - val_accuracy: 0.8273\n",
      "Epoch 95/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.4361 - accuracy: 0.8465 - val_loss: 0.5950 - val_accuracy: 0.8164\n",
      "Epoch 96/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.4351 - accuracy: 0.8469 - val_loss: 0.5115 - val_accuracy: 0.8333\n",
      "Epoch 97/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.4358 - accuracy: 0.8481 - val_loss: 0.6620 - val_accuracy: 0.8007\n",
      "Epoch 98/300\n",
      "3125/3125 [==============================] - 142s 45ms/step - loss: 0.4322 - accuracy: 0.8483 - val_loss: 0.5514 - val_accuracy: 0.8275\n",
      "Epoch 99/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4309 - accuracy: 0.8484 - val_loss: 0.5632 - val_accuracy: 0.8215\n",
      "Epoch 100/300\n",
      "3125/3125 [==============================] - 141s 45ms/step - loss: 0.4323 - accuracy: 0.8482 - val_loss: 0.5769 - val_accuracy: 0.8188\n",
      "Epoch 101/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.4312 - accuracy: 0.8498 - val_loss: 0.5562 - val_accuracy: 0.8192\n",
      "Epoch 102/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.4323 - accuracy: 0.8484 - val_loss: 0.5278 - val_accuracy: 0.8339\n",
      "Epoch 103/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4301 - accuracy: 0.8486 - val_loss: 0.5128 - val_accuracy: 0.8339\n",
      "Epoch 104/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.4274 - accuracy: 0.8498 - val_loss: 0.5479 - val_accuracy: 0.8258\n",
      "Epoch 105/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.4220 - accuracy: 0.8515 - val_loss: 0.5185 - val_accuracy: 0.8355\n",
      "Epoch 106/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4268 - accuracy: 0.8487 - val_loss: 0.6201 - val_accuracy: 0.8067\n",
      "Epoch 107/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.4262 - accuracy: 0.8497 - val_loss: 0.5746 - val_accuracy: 0.8176\n",
      "Epoch 108/300\n",
      "3125/3125 [==============================] - 141s 45ms/step - loss: 0.4240 - accuracy: 0.8495 - val_loss: 0.5623 - val_accuracy: 0.8244\n",
      "Epoch 109/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 142s 46ms/step - loss: 0.4219 - accuracy: 0.8523 - val_loss: 0.5520 - val_accuracy: 0.8269\n",
      "Epoch 110/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.4211 - accuracy: 0.8525 - val_loss: 0.5709 - val_accuracy: 0.8235\n",
      "Epoch 111/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4180 - accuracy: 0.8538 - val_loss: 0.5071 - val_accuracy: 0.8376\n",
      "Epoch 112/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.4205 - accuracy: 0.8506 - val_loss: 0.5304 - val_accuracy: 0.8320\n",
      "Epoch 113/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4206 - accuracy: 0.8522 - val_loss: 0.5283 - val_accuracy: 0.8311\n",
      "Epoch 114/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4174 - accuracy: 0.8537 - val_loss: 0.5500 - val_accuracy: 0.8255\n",
      "Epoch 115/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.4204 - accuracy: 0.8524 - val_loss: 0.5651 - val_accuracy: 0.8241\n",
      "Epoch 116/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4200 - accuracy: 0.8530 - val_loss: 0.5089 - val_accuracy: 0.8374\n",
      "Epoch 117/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4161 - accuracy: 0.8541 - val_loss: 0.5453 - val_accuracy: 0.8274\n",
      "Epoch 118/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4174 - accuracy: 0.8514 - val_loss: 0.5828 - val_accuracy: 0.8216\n",
      "Epoch 119/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.4159 - accuracy: 0.8539 - val_loss: 0.6239 - val_accuracy: 0.8114\n",
      "Epoch 120/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4153 - accuracy: 0.8540 - val_loss: 0.5192 - val_accuracy: 0.8362\n",
      "Epoch 121/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4146 - accuracy: 0.8549 - val_loss: 0.5449 - val_accuracy: 0.8290\n",
      "Epoch 122/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4119 - accuracy: 0.8540 - val_loss: 0.5271 - val_accuracy: 0.8320\n",
      "Epoch 123/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4137 - accuracy: 0.8541 - val_loss: 0.6068 - val_accuracy: 0.8059\n",
      "Epoch 124/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.4101 - accuracy: 0.8568 - val_loss: 0.5358 - val_accuracy: 0.8284\n",
      "Epoch 125/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.4110 - accuracy: 0.8554 - val_loss: 0.5843 - val_accuracy: 0.8206\n",
      "Epoch 126/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4136 - accuracy: 0.8545 - val_loss: 0.5679 - val_accuracy: 0.8198\n",
      "Epoch 127/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.4101 - accuracy: 0.8545 - val_loss: 0.5778 - val_accuracy: 0.8224\n",
      "Epoch 128/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4079 - accuracy: 0.8557 - val_loss: 0.5159 - val_accuracy: 0.8375\n",
      "Epoch 129/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.4035 - accuracy: 0.8583 - val_loss: 0.5177 - val_accuracy: 0.8392\n",
      "Epoch 130/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.4094 - accuracy: 0.8561 - val_loss: 0.5941 - val_accuracy: 0.8200\n",
      "Epoch 131/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.4090 - accuracy: 0.8558 - val_loss: 0.5276 - val_accuracy: 0.8365\n",
      "Epoch 132/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.4034 - accuracy: 0.8567 - val_loss: 0.5427 - val_accuracy: 0.8269\n",
      "Epoch 133/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4047 - accuracy: 0.8586 - val_loss: 0.5623 - val_accuracy: 0.8247\n",
      "Epoch 134/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.4031 - accuracy: 0.8579 - val_loss: 0.5768 - val_accuracy: 0.8186\n",
      "Epoch 135/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.4000 - accuracy: 0.8601 - val_loss: 0.5247 - val_accuracy: 0.8357\n",
      "Epoch 136/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.4049 - accuracy: 0.8574 - val_loss: 0.5259 - val_accuracy: 0.8357\n",
      "Epoch 137/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.4031 - accuracy: 0.8575 - val_loss: 0.5431 - val_accuracy: 0.8308\n",
      "Epoch 138/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.3995 - accuracy: 0.8587 - val_loss: 0.5137 - val_accuracy: 0.8394\n",
      "Epoch 139/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3986 - accuracy: 0.8591 - val_loss: 0.5423 - val_accuracy: 0.8312\n",
      "Epoch 140/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3974 - accuracy: 0.8596 - val_loss: 0.5011 - val_accuracy: 0.8410\n",
      "Epoch 141/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.4039 - accuracy: 0.8579 - val_loss: 0.5551 - val_accuracy: 0.8246\n",
      "Epoch 142/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3952 - accuracy: 0.8587 - val_loss: 0.5189 - val_accuracy: 0.8392\n",
      "Epoch 143/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3920 - accuracy: 0.8617 - val_loss: 0.5137 - val_accuracy: 0.8391\n",
      "Epoch 144/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3959 - accuracy: 0.8613 - val_loss: 0.5158 - val_accuracy: 0.8366\n",
      "Epoch 145/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3920 - accuracy: 0.8621 - val_loss: 0.5087 - val_accuracy: 0.8406\n",
      "Epoch 146/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3986 - accuracy: 0.8585 - val_loss: 0.5400 - val_accuracy: 0.8290\n",
      "Epoch 147/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3978 - accuracy: 0.8613 - val_loss: 0.5375 - val_accuracy: 0.8316\n",
      "Epoch 148/300\n",
      "3125/3125 [==============================] - 142s 45ms/step - loss: 0.3956 - accuracy: 0.8620 - val_loss: 0.5277 - val_accuracy: 0.8348\n",
      "Epoch 149/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3936 - accuracy: 0.8628 - val_loss: 0.5933 - val_accuracy: 0.8209\n",
      "Epoch 150/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3957 - accuracy: 0.8608 - val_loss: 0.5352 - val_accuracy: 0.8339\n",
      "Epoch 151/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3915 - accuracy: 0.8616 - val_loss: 0.5185 - val_accuracy: 0.8371\n",
      "Epoch 152/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.3891 - accuracy: 0.8627 - val_loss: 0.5306 - val_accuracy: 0.8334ss: 0\n",
      "Epoch 153/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3910 - accuracy: 0.8618 - val_loss: 0.5451 - val_accuracy: 0.8302\n",
      "Epoch 154/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3863 - accuracy: 0.8640 - val_loss: 0.5275 - val_accuracy: 0.8374\n",
      "Epoch 155/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3915 - accuracy: 0.8627 - val_loss: 0.5284 - val_accuracy: 0.8410\n",
      "Epoch 156/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.3920 - accuracy: 0.8610 - val_loss: 0.5653 - val_accuracy: 0.8274\n",
      "Epoch 157/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3864 - accuracy: 0.8633 - val_loss: 0.5457 - val_accuracy: 0.8313\n",
      "Epoch 158/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3886 - accuracy: 0.8653 - val_loss: 0.5092 - val_accuracy: 0.8433\n",
      "Epoch 159/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3860 - accuracy: 0.8641 - val_loss: 0.5857 - val_accuracy: 0.8240\n",
      "Epoch 160/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3911 - accuracy: 0.8615 - val_loss: 0.5383 - val_accuracy: 0.8352\n",
      "Epoch 161/300\n",
      "3125/3125 [==============================] - 142s 45ms/step - loss: 0.3861 - accuracy: 0.8623 - val_loss: 0.5554 - val_accuracy: 0.8302\n",
      "Epoch 162/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3873 - accuracy: 0.8637 - val_loss: 0.5661 - val_accuracy: 0.8263\n",
      "Epoch 163/300\n",
      "3125/3125 [==============================] - 142s 45ms/step - loss: 0.3851 - accuracy: 0.8626 - val_loss: 0.5233 - val_accuracy: 0.8338\n",
      "Epoch 164/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3877 - accuracy: 0.8628 - val_loss: 0.5489 - val_accuracy: 0.8294\n",
      "Epoch 165/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.3848 - accuracy: 0.8640 - val_loss: 0.5243 - val_accuracy: 0.8393\n",
      "Epoch 166/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3817 - accuracy: 0.8652 - val_loss: 0.5286 - val_accuracy: 0.8396\n",
      "Epoch 167/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3861 - accuracy: 0.8651 - val_loss: 0.5004 - val_accuracy: 0.8409\n",
      "Epoch 168/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3862 - accuracy: 0.8643 - val_loss: 0.4986 - val_accuracy: 0.8464\n",
      "Epoch 169/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3883 - accuracy: 0.8637 - val_loss: 0.5445 - val_accuracy: 0.8308\n",
      "Epoch 170/300\n",
      "3125/3125 [==============================] - 143s 46ms/step - loss: 0.3860 - accuracy: 0.8664 - val_loss: 0.5841 - val_accuracy: 0.8223\n",
      "Epoch 171/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3819 - accuracy: 0.8650 - val_loss: 0.4892 - val_accuracy: 0.8473\n",
      "Epoch 172/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3816 - accuracy: 0.8653 - val_loss: 0.5875 - val_accuracy: 0.8256\n",
      "Epoch 173/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3822 - accuracy: 0.8654 - val_loss: 0.4888 - val_accuracy: 0.8488\n",
      "Epoch 174/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3832 - accuracy: 0.8644 - val_loss: 0.5250 - val_accuracy: 0.8393\n",
      "Epoch 175/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3830 - accuracy: 0.8638 - val_loss: 0.5128 - val_accuracy: 0.8388\n",
      "Epoch 176/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3801 - accuracy: 0.8639 - val_loss: 0.5428 - val_accuracy: 0.8319\n",
      "Epoch 177/300\n",
      "3125/3125 [==============================] - 143s 46ms/step - loss: 0.3793 - accuracy: 0.8668 - val_loss: 0.5072 - val_accuracy: 0.8460\n",
      "Epoch 178/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3814 - accuracy: 0.8650 - val_loss: 0.4982 - val_accuracy: 0.8463\n",
      "Epoch 179/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3751 - accuracy: 0.8669 - val_loss: 0.4759 - val_accuracy: 0.8469\n",
      "Epoch 180/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3797 - accuracy: 0.8676 - val_loss: 0.5541 - val_accuracy: 0.8326\n",
      "Epoch 181/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3771 - accuracy: 0.8664 - val_loss: 0.5761 - val_accuracy: 0.8282\n",
      "Epoch 182/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3800 - accuracy: 0.8651 - val_loss: 0.5264 - val_accuracy: 0.8385\n",
      "Epoch 183/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3778 - accuracy: 0.8660 - val_loss: 0.5524 - val_accuracy: 0.8314\n",
      "Epoch 184/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3769 - accuracy: 0.8675 - val_loss: 0.4934 - val_accuracy: 0.8448\n",
      "Epoch 185/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3774 - accuracy: 0.8666 - val_loss: 0.5391 - val_accuracy: 0.8363\n",
      "Epoch 186/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3802 - accuracy: 0.8652 - val_loss: 0.5375 - val_accuracy: 0.8330\n",
      "Epoch 187/300\n",
      "3125/3125 [==============================] - 149s 48ms/step - loss: 0.3793 - accuracy: 0.8666 - val_loss: 0.5431 - val_accuracy: 0.8351\n",
      "Epoch 188/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3826 - accuracy: 0.8648 - val_loss: 0.5257 - val_accuracy: 0.8372\n",
      "Epoch 189/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3678 - accuracy: 0.8699 - val_loss: 0.4918 - val_accuracy: 0.8469\n",
      "Epoch 190/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3750 - accuracy: 0.8676 - val_loss: 0.5148 - val_accuracy: 0.8382\n",
      "Epoch 191/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3738 - accuracy: 0.8695 - val_loss: 0.5144 - val_accuracy: 0.8410\n",
      "Epoch 192/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3783 - accuracy: 0.8683 - val_loss: 0.5703 - val_accuracy: 0.8264\n",
      "Epoch 193/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3725 - accuracy: 0.8691 - val_loss: 0.5428 - val_accuracy: 0.8343\n",
      "Epoch 194/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3679 - accuracy: 0.8682 - val_loss: 0.4920 - val_accuracy: 0.8474\n",
      "Epoch 195/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3683 - accuracy: 0.8710 - val_loss: 0.4988 - val_accuracy: 0.8435\n",
      "Epoch 196/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3707 - accuracy: 0.8692 - val_loss: 0.5418 - val_accuracy: 0.8354\n",
      "Epoch 197/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3688 - accuracy: 0.8703 - val_loss: 0.4901 - val_accuracy: 0.8458\n",
      "Epoch 198/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3693 - accuracy: 0.8698 - val_loss: 0.5037 - val_accuracy: 0.8443\n",
      "Epoch 199/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3675 - accuracy: 0.8699 - val_loss: 0.5253 - val_accuracy: 0.8389\n",
      "Epoch 200/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3710 - accuracy: 0.8691 - val_loss: 0.5121 - val_accuracy: 0.8421\n",
      "Epoch 201/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3709 - accuracy: 0.8693 - val_loss: 0.5393 - val_accuracy: 0.8305\n",
      "Epoch 202/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3687 - accuracy: 0.8716 - val_loss: 0.5854 - val_accuracy: 0.8242\n",
      "Epoch 203/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3697 - accuracy: 0.8703 - val_loss: 0.5558 - val_accuracy: 0.8301\n",
      "Epoch 204/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3671 - accuracy: 0.8699 - val_loss: 0.5404 - val_accuracy: 0.8358\n",
      "Epoch 205/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3697 - accuracy: 0.8688 - val_loss: 0.5698 - val_accuracy: 0.8291\n",
      "Epoch 206/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3613 - accuracy: 0.8715 - val_loss: 0.5264 - val_accuracy: 0.8400\n",
      "Epoch 207/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3675 - accuracy: 0.8711 - val_loss: 0.5382 - val_accuracy: 0.8373\n",
      "Epoch 208/300\n",
      "3125/3125 [==============================] - 143s 46ms/step - loss: 0.3674 - accuracy: 0.8701 - val_loss: 0.5501 - val_accuracy: 0.8335\n",
      "Epoch 209/300\n",
      "3125/3125 [==============================] - 143s 46ms/step - loss: 0.3665 - accuracy: 0.8699 - val_loss: 0.5592 - val_accuracy: 0.8291\n",
      "Epoch 210/300\n",
      "3125/3125 [==============================] - 142s 45ms/step - loss: 0.3669 - accuracy: 0.8694 - val_loss: 0.5157 - val_accuracy: 0.8409\n",
      "Epoch 211/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3651 - accuracy: 0.8727 - val_loss: 0.5219 - val_accuracy: 0.8391\n",
      "Epoch 212/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3627 - accuracy: 0.8723 - val_loss: 0.5513 - val_accuracy: 0.8339\n",
      "Epoch 213/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3631 - accuracy: 0.8720 - val_loss: 0.5484 - val_accuracy: 0.8320\n",
      "Epoch 214/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3634 - accuracy: 0.8710 - val_loss: 0.5351 - val_accuracy: 0.8367\n",
      "Epoch 215/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3625 - accuracy: 0.8711 - val_loss: 0.4898 - val_accuracy: 0.8481\n",
      "Epoch 216/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3650 - accuracy: 0.8713 - val_loss: 0.5032 - val_accuracy: 0.8446acy\n",
      "Epoch 217/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3661 - accuracy: 0.8723 - val_loss: 0.5238 - val_accuracy: 0.8418\n",
      "Epoch 218/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3658 - accuracy: 0.8708 - val_loss: 0.5856 - val_accuracy: 0.8267\n",
      "Epoch 219/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3617 - accuracy: 0.8717 - val_loss: 0.4858 - val_accuracy: 0.8492\n",
      "Epoch 220/300\n",
      "3125/3125 [==============================] - 149s 48ms/step - loss: 0.3611 - accuracy: 0.8728 - val_loss: 0.5274 - val_accuracy: 0.8395\n",
      "Epoch 221/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3605 - accuracy: 0.8724 - val_loss: 0.4972 - val_accuracy: 0.8462\n",
      "Epoch 222/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3598 - accuracy: 0.8714 - val_loss: 0.5272 - val_accuracy: 0.8368\n",
      "Epoch 223/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3592 - accuracy: 0.8727 - val_loss: 0.5128 - val_accuracy: 0.8424\n",
      "Epoch 224/300\n",
      "3125/3125 [==============================] - 149s 48ms/step - loss: 0.3607 - accuracy: 0.8728 - val_loss: 0.5196 - val_accuracy: 0.8403\n",
      "Epoch 225/300\n",
      "3125/3125 [==============================] - 150s 48ms/step - loss: 0.3620 - accuracy: 0.8716 - val_loss: 0.4708 - val_accuracy: 0.8518\n",
      "Epoch 226/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3595 - accuracy: 0.8733 - val_loss: 0.5174 - val_accuracy: 0.8393\n",
      "Epoch 227/300\n",
      "3125/3125 [==============================] - 149s 48ms/step - loss: 0.3657 - accuracy: 0.8710 - val_loss: 0.5066 - val_accuracy: 0.8429\n",
      "Epoch 228/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3621 - accuracy: 0.8711 - val_loss: 0.5549 - val_accuracy: 0.8331\n",
      "Epoch 229/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3586 - accuracy: 0.8739 - val_loss: 0.5239 - val_accuracy: 0.8418\n",
      "Epoch 230/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3543 - accuracy: 0.8750 - val_loss: 0.5978 - val_accuracy: 0.8279\n",
      "Epoch 231/300\n",
      "3125/3125 [==============================] - 143s 46ms/step - loss: 0.3545 - accuracy: 0.8748 - val_loss: 0.5015 - val_accuracy: 0.8494\n",
      "Epoch 232/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3582 - accuracy: 0.8729 - val_loss: 0.5087 - val_accuracy: 0.8438\n",
      "Epoch 233/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3564 - accuracy: 0.8746 - val_loss: 0.5207 - val_accuracy: 0.8434\n",
      "Epoch 234/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3611 - accuracy: 0.8716 - val_loss: 0.5099 - val_accuracy: 0.8422\n",
      "Epoch 235/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3544 - accuracy: 0.8748 - val_loss: 0.4884 - val_accuracy: 0.8490\n",
      "Epoch 236/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3573 - accuracy: 0.8751 - val_loss: 0.4990 - val_accuracy: 0.8467\n",
      "Epoch 237/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3578 - accuracy: 0.8736 - val_loss: 0.5366 - val_accuracy: 0.8364\n",
      "Epoch 238/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3600 - accuracy: 0.8725 - val_loss: 0.5119 - val_accuracy: 0.8441\n",
      "Epoch 239/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3546 - accuracy: 0.8752 - val_loss: 0.5280 - val_accuracy: 0.8353\n",
      "Epoch 240/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3560 - accuracy: 0.8734 - val_loss: 0.5122 - val_accuracy: 0.8414\n",
      "Epoch 241/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3538 - accuracy: 0.8756 - val_loss: 0.4924 - val_accuracy: 0.8525\n",
      "Epoch 242/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3527 - accuracy: 0.8762 - val_loss: 0.5160 - val_accuracy: 0.8414\n",
      "Epoch 243/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3592 - accuracy: 0.8727 - val_loss: 0.4816 - val_accuracy: 0.8487\n",
      "Epoch 244/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3514 - accuracy: 0.8756 - val_loss: 0.4883 - val_accuracy: 0.8513\n",
      "Epoch 245/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3570 - accuracy: 0.8734 - val_loss: 0.5069 - val_accuracy: 0.8444\n",
      "Epoch 246/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3540 - accuracy: 0.8737 - val_loss: 0.5049 - val_accuracy: 0.8472\n",
      "Epoch 247/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3529 - accuracy: 0.8744 - val_loss: 0.5290 - val_accuracy: 0.8411\n",
      "Epoch 248/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3515 - accuracy: 0.8753 - val_loss: 0.4813 - val_accuracy: 0.8552\n",
      "Epoch 249/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3503 - accuracy: 0.8762 - val_loss: 0.4956 - val_accuracy: 0.8521\n",
      "Epoch 250/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3524 - accuracy: 0.8761 - val_loss: 0.5281 - val_accuracy: 0.8410\n",
      "Epoch 251/300\n",
      "3125/3125 [==============================] - 142s 46ms/step - loss: 0.3526 - accuracy: 0.8745 - val_loss: 0.5269 - val_accuracy: 0.8409\n",
      "Epoch 252/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3511 - accuracy: 0.8750 - val_loss: 0.5039 - val_accuracy: 0.8467\n",
      "Epoch 253/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3525 - accuracy: 0.8762 - val_loss: 0.5626 - val_accuracy: 0.8370\n",
      "Epoch 254/300\n",
      "3125/3125 [==============================] - 142s 46ms/step - loss: 0.3533 - accuracy: 0.8733 - val_loss: 0.4811 - val_accuracy: 0.8527\n",
      "Epoch 255/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3499 - accuracy: 0.8762 - val_loss: 0.4790 - val_accuracy: 0.8539\n",
      "Epoch 256/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3527 - accuracy: 0.8747 - val_loss: 0.5221 - val_accuracy: 0.8441\n",
      "Epoch 257/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3552 - accuracy: 0.8741 - val_loss: 0.5197 - val_accuracy: 0.8438\n",
      "Epoch 258/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3517 - accuracy: 0.8751 - val_loss: 0.4794 - val_accuracy: 0.8524\n",
      "Epoch 259/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3527 - accuracy: 0.8758 - val_loss: 0.5479 - val_accuracy: 0.8337\n",
      "Epoch 260/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3478 - accuracy: 0.8768 - val_loss: 0.5313 - val_accuracy: 0.8405\n",
      "Epoch 261/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3485 - accuracy: 0.8765 - val_loss: 0.5231 - val_accuracy: 0.8407\n",
      "Epoch 262/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3500 - accuracy: 0.8752 - val_loss: 0.5034 - val_accuracy: 0.8488\n",
      "Epoch 263/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3474 - accuracy: 0.8765 - val_loss: 0.4884 - val_accuracy: 0.8498\n",
      "Epoch 264/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3485 - accuracy: 0.8768 - val_loss: 0.5341 - val_accuracy: 0.8402\n",
      "Epoch 265/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3509 - accuracy: 0.8778 - val_loss: 0.5038 - val_accuracy: 0.8468\n",
      "Epoch 266/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3472 - accuracy: 0.8764 - val_loss: 0.5196 - val_accuracy: 0.8415\n",
      "Epoch 267/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3510 - accuracy: 0.8770 - val_loss: 0.5055 - val_accuracy: 0.8478\n",
      "Epoch 268/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3486 - accuracy: 0.8766 - val_loss: 0.5134 - val_accuracy: 0.8439\n",
      "Epoch 269/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3458 - accuracy: 0.8785 - val_loss: 0.5152 - val_accuracy: 0.8466\n",
      "Epoch 270/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3463 - accuracy: 0.8772 - val_loss: 0.4887 - val_accuracy: 0.8499\n",
      "Epoch 271/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3494 - accuracy: 0.8759 - val_loss: 0.4982 - val_accuracy: 0.8511\n",
      "Epoch 272/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3486 - accuracy: 0.8766 - val_loss: 0.5264 - val_accuracy: 0.8424\n",
      "Epoch 273/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3479 - accuracy: 0.8771 - val_loss: 0.5321 - val_accuracy: 0.8410\n",
      "Epoch 274/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3508 - accuracy: 0.8773 - val_loss: 0.5205 - val_accuracy: 0.8411\n",
      "Epoch 275/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3479 - accuracy: 0.8770 - val_loss: 0.5445 - val_accuracy: 0.8359\n",
      "Epoch 276/300\n",
      "3125/3125 [==============================] - 142s 45ms/step - loss: 0.3460 - accuracy: 0.8761 - val_loss: 0.4752 - val_accuracy: 0.8542\n",
      "Epoch 277/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3485 - accuracy: 0.8771 - val_loss: 0.4866 - val_accuracy: 0.8520\n",
      "Epoch 278/300\n",
      "3125/3125 [==============================] - 145s 47ms/step - loss: 0.3457 - accuracy: 0.8772 - val_loss: 0.4866 - val_accuracy: 0.8509\n",
      "Epoch 279/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3473 - accuracy: 0.8782 - val_loss: 0.5034 - val_accuracy: 0.8476\n",
      "Epoch 280/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3518 - accuracy: 0.8756 - val_loss: 0.5212 - val_accuracy: 0.8406\n",
      "Epoch 281/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3422 - accuracy: 0.8784 - val_loss: 0.5090 - val_accuracy: 0.8470\n",
      "Epoch 282/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3448 - accuracy: 0.8784 - val_loss: 0.4937 - val_accuracy: 0.8540\n",
      "Epoch 283/300\n",
      "3125/3125 [==============================] - 142s 45ms/step - loss: 0.3441 - accuracy: 0.8801 - val_loss: 0.5127 - val_accuracy: 0.8428\n",
      "Epoch 284/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3429 - accuracy: 0.8777 - val_loss: 0.4943 - val_accuracy: 0.8505\n",
      "Epoch 285/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3446 - accuracy: 0.8791 - val_loss: 0.5344 - val_accuracy: 0.8398\n",
      "Epoch 286/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.3439 - accuracy: 0.8781 - val_loss: 0.4946 - val_accuracy: 0.8509\n",
      "Epoch 287/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3433 - accuracy: 0.8793 - val_loss: 0.5268 - val_accuracy: 0.8433\n",
      "Epoch 288/300\n",
      "3125/3125 [==============================] - 142s 45ms/step - loss: 0.3439 - accuracy: 0.8775 - val_loss: 0.5077 - val_accuracy: 0.8468\n",
      "Epoch 289/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3421 - accuracy: 0.8789 - val_loss: 0.5184 - val_accuracy: 0.8429\n",
      "Epoch 290/300\n",
      "3125/3125 [==============================] - 147s 47ms/step - loss: 0.3486 - accuracy: 0.8769 - val_loss: 0.5379 - val_accuracy: 0.8366\n",
      "Epoch 291/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3403 - accuracy: 0.8804 - val_loss: 0.4886 - val_accuracy: 0.8525\n",
      "Epoch 292/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3405 - accuracy: 0.8786 - val_loss: 0.5250 - val_accuracy: 0.8423\n",
      "Epoch 293/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3455 - accuracy: 0.8787 - val_loss: 0.5148 - val_accuracy: 0.8438\n",
      "Epoch 294/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3392 - accuracy: 0.8803 - val_loss: 0.4945 - val_accuracy: 0.8485\n",
      "Epoch 295/300\n",
      "3125/3125 [==============================] - 148s 47ms/step - loss: 0.3470 - accuracy: 0.8773 - val_loss: 0.5396 - val_accuracy: 0.8396\n",
      "Epoch 296/300\n",
      "3125/3125 [==============================] - 144s 46ms/step - loss: 0.3430 - accuracy: 0.8794 - val_loss: 0.5082 - val_accuracy: 0.8468\n",
      "Epoch 297/300\n",
      "3125/3125 [==============================] - 142s 45ms/step - loss: 0.3412 - accuracy: 0.8792 - val_loss: 0.5310 - val_accuracy: 0.8430\n",
      "Epoch 298/300\n",
      "3125/3125 [==============================] - 146s 47ms/step - loss: 0.3426 - accuracy: 0.8793 - val_loss: 0.4799 - val_accuracy: 0.8549\n",
      "Epoch 299/300\n",
      "3125/3125 [==============================] - 149s 48ms/step - loss: 0.3386 - accuracy: 0.8792 - val_loss: 0.4840 - val_accuracy: 0.8536\n",
      "Epoch 300/300\n",
      "3125/3125 [==============================] - 145s 46ms/step - loss: 0.3451 - accuracy: 0.8760 - val_loss: 0.5379 - val_accuracy: 0.8378\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history.history['accuracy']\n",
    "loss_val = history.history['val_accuracy']\n",
    "epochs = range(epochs)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy of DENSENET\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-xnZ5HFOtE-2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 15ms/step - loss: 0.5379 - accuracy: 0.8378\n",
      "Test loss: 0.5378697514533997\n",
      "Test accuracy: 0.8378000259399414\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model_1.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Y6e0sanotfNN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save the trained weights in to .h5 format\n",
    "model_1.save_weights(\"DNST_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "rXg8LZXBs10u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model_1, to_file='model_without_bc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DENSENET MODEL WITHOUT BOTTLENECK WITH AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "num_classes = 10\n",
    "epochs =300\n",
    "step_size =64\n",
    "l = 12\n",
    "num_filter = 12\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Blosck\n",
    "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_model(input_shape = (32,32,3), n_classes = 10):\n",
    "    X_input = Input(shape=(img_height, img_width, channel))\n",
    "    First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(X_input)\n",
    "    \n",
    "    First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "    First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "    Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "    Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "    Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "    Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "    Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "    output = output_layer(Last_Block)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 12)   324         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 12)   48          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 12)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 6)    648         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 6)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 18)   0           conv2d[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 18)   72          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 18)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 6)    972         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 6)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 24)   0           concatenate[0][0]                \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 24)   96          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 24)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 6)    1296        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 6)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 30)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 30)   120         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 30)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 6)    1620        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 6)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 36)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 36)   144         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 36)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 6)    1944        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 6)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 42)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 42)   168         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 42)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 6)    2268        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 6)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 48)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 6)    2592        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 6)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 54)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 54)   216         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 54)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 6)    2916        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 6)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 60)   0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 60)   240         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 60)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 6)    3240        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 6)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 66)   0           concatenate_7[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 66)   264         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 66)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 6)    3564        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 6)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 72)   0           concatenate_8[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 72)   288         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 72)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 6)    3888        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 6)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 78)   0           concatenate_9[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 78)   312         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 78)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 6)    4212        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 6)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 84)   0           concatenate_10[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 84)   336         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 84)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 6)    504         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 6)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 6)    0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 6)    24          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 6)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 6)    324         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 6)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 12)   0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 12)   48          concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 12)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 6)    648         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 6)    0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 18)   0           concatenate_12[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 18)   72          concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 18)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 6)    972         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 6)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 24)   0           concatenate_13[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 24)   96          concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 24)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 6)    1296        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 6)    0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 30)   0           concatenate_14[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 30)   120         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 30)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 6)    1620        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 6)    0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 36)   0           concatenate_15[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 36)   144         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 36)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 6)    1944        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 6)    0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 42)   0           concatenate_16[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 42)   168         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 42)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 6)    2268        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 6)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 48)   0           concatenate_17[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   192         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 6)    2592        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 6)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 54)   0           concatenate_18[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 54)   216         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 54)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 6)    2916        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 6)    0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 60)   0           concatenate_19[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 60)   240         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 60)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 6)    3240        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 6)    0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 66)   0           concatenate_20[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 66)   264         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 66)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 6)    3564        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 6)    0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 72)   0           concatenate_21[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 72)   288         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 72)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 6)    3888        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 6)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 78)   0           concatenate_22[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 78)   312         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 78)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 6)    468         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 6)    0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 6)      0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 6)      24          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 6)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 6)      324         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 6)      0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 12)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 12)     48          concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 12)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 6)      648         activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 8, 8, 6)      0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 18)     0           concatenate_24[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 18)     72          concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 18)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 6)      972         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 8, 8, 6)      0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 24)     0           concatenate_25[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 24)     96          concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 24)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 6)      1296        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 8, 8, 6)      0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 30)     0           concatenate_26[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 30)     120         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 30)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 6)      1620        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 8, 8, 6)      0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 36)     0           concatenate_27[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 36)     144         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 36)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 6)      1944        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 8, 8, 6)      0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 42)     0           concatenate_28[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 42)     168         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 42)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 6)      2268        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 8, 8, 6)      0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 48)     0           concatenate_29[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 48)     192         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 48)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 6)      2592        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 8, 8, 6)      0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 54)     0           concatenate_30[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 54)     216         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 54)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 6)      2916        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 8, 8, 6)      0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 60)     0           concatenate_31[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 60)     240         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 60)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 6)      3240        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 8, 8, 6)      0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 66)     0           concatenate_32[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 66)     264         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 66)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 6)      3564        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 8, 8, 6)      0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 72)     0           concatenate_33[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 72)     288         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 72)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 6)      3888        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 8, 8, 6)      0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 78)     0           concatenate_34[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 78)     312         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 78)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 6)      468         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 8, 8, 6)      0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 6)      0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 4, 4, 6)      24          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 6)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 4, 4, 6)      324         activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 4, 4, 6)      0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 12)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 12)     48          concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 12)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 4, 4, 6)      648         activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 4, 4, 6)      0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 18)     0           concatenate_36[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 4, 4, 18)     72          concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 18)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 4, 4, 6)      972         activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 4, 4, 6)      0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 24)     0           concatenate_37[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 4, 24)     96          concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 24)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 4, 4, 6)      1296        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 4, 4, 6)      0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 30)     0           concatenate_38[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 4, 30)     120         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 30)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 4, 4, 6)      1620        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 4, 4, 6)      0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 36)     0           concatenate_39[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 36)     144         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 36)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 4, 4, 6)      1944        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 4, 4, 6)      0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 42)     0           concatenate_40[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 42)     168         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 42)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 4, 6)      2268        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 4, 4, 6)      0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 48)     0           concatenate_41[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 48)     192         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 48)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 4, 6)      2592        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 4, 4, 6)      0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 54)     0           concatenate_42[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 54)     216         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 54)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 4, 4, 6)      2916        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 4, 4, 6)      0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 60)     0           concatenate_43[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 60)     240         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 60)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 4, 4, 6)      3240        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 4, 4, 6)      0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 66)     0           concatenate_44[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 66)     264         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 66)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 4, 4, 6)      3564        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 4, 4, 6)      0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 72)     0           concatenate_45[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 72)     288         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 72)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 4, 4, 6)      3888        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 4, 4, 6)      0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 78)     0           concatenate_46[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 78)     312         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 78)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 78)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 312)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           3130        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 118,918\n",
      "Trainable params: 114,394\n",
      "Non-trainable params: 4,524\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = dense_model(input_shape = (32,32,3), n_classes = 10)\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_model_1(X_train, y_train, X_test, y_test, batch_size, step_size, epochs):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10, # rotation\n",
    "        width_shift_range=0.2, # horizontal shift\n",
    "        height_shift_range=0.2, # vertical shift\n",
    "        zoom_range=0.2, # zoom\n",
    "        horizontal_flip=True, # horizontal flip\n",
    "        )\n",
    "    train_data = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "    test_data  = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "    # train_steps = train_data.samples // batch_size\n",
    "    # val_steps = test_data.samples // batch_size\n",
    "    train_steps = int(X_train.shape[0] / step_size)\n",
    "    val_steps = int(X_test.shape[0] / step_size)\n",
    "    history = model_1.fit(train_data, epochs=epochs,steps_per_epoch=train_steps,\n",
    "                              validation_data=test_data,validation_steps=val_steps)\n",
    "    # Test the model\n",
    "    score = model_1.evaluate(X_test, y_test, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Save the trained weights in to .h5 format\n",
    "    model_1.save_weights(\"DNST_without_bc_with_augmentation.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "    loss_train = history.history['accuracy']\n",
    "    loss_val = history.history['val_accuracy']\n",
    "    epochs = range(epochs)\n",
    "    plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "    plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy of DENSENET-aug\")\n",
    "    plt.show()\n",
    "\n",
    "    tf.keras.utils.plot_model(model_1, to_file='model_without_bc_aug.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 2.1295 - accuracy: 0.2111 - val_loss: 2.0225 - val_accuracy: 0.2845\n",
      "Epoch 2/300\n",
      "781/781 [==============================] - 25s 31ms/step - loss: 1.9495 - accuracy: 0.2722 - val_loss: 1.9086 - val_accuracy: 0.2917\n",
      "Epoch 3/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.8920 - accuracy: 0.2942 - val_loss: 1.7395 - val_accuracy: 0.3782\n",
      "Epoch 4/300\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 1.8254 - accuracy: 0.3254 - val_loss: 1.7838 - val_accuracy: 0.3494\n",
      "Epoch 5/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.7634 - accuracy: 0.3499 - val_loss: 1.7429 - val_accuracy: 0.3742\n",
      "Epoch 6/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.7240 - accuracy: 0.3673 - val_loss: 1.8941 - val_accuracy: 0.3478\n",
      "Epoch 7/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.6903 - accuracy: 0.3771 - val_loss: 1.6719 - val_accuracy: 0.4383\n",
      "Epoch 8/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.6676 - accuracy: 0.3899 - val_loss: 1.6641 - val_accuracy: 0.4175\n",
      "Epoch 9/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.6158 - accuracy: 0.4187 - val_loss: 1.5938 - val_accuracy: 0.4239\n",
      "Epoch 10/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.5944 - accuracy: 0.4150 - val_loss: 1.7005 - val_accuracy: 0.4119\n",
      "Epoch 11/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.5707 - accuracy: 0.4267 - val_loss: 1.5662 - val_accuracy: 0.4367\n",
      "Epoch 12/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.5724 - accuracy: 0.4241 - val_loss: 1.6883 - val_accuracy: 0.4383\n",
      "Epoch 13/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.5173 - accuracy: 0.4533 - val_loss: 1.4850 - val_accuracy: 0.4599\n",
      "Epoch 14/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.5149 - accuracy: 0.4489 - val_loss: 1.6243 - val_accuracy: 0.4631\n",
      "Epoch 15/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.4935 - accuracy: 0.4651 - val_loss: 1.5974 - val_accuracy: 0.4447\n",
      "Epoch 16/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.5023 - accuracy: 0.4528 - val_loss: 1.4251 - val_accuracy: 0.4880\n",
      "Epoch 17/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.4782 - accuracy: 0.4573 - val_loss: 1.5655 - val_accuracy: 0.4639\n",
      "Epoch 18/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.4564 - accuracy: 0.4706 - val_loss: 1.4224 - val_accuracy: 0.5032\n",
      "Epoch 19/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.4572 - accuracy: 0.4657 - val_loss: 1.4363 - val_accuracy: 0.4928\n",
      "Epoch 20/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.4375 - accuracy: 0.4778 - val_loss: 1.5363 - val_accuracy: 0.4688\n",
      "Epoch 21/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.4059 - accuracy: 0.4846 - val_loss: 1.3742 - val_accuracy: 0.5208\n",
      "Epoch 22/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.3970 - accuracy: 0.4955 - val_loss: 1.4916 - val_accuracy: 0.4872\n",
      "Epoch 23/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.3832 - accuracy: 0.4965 - val_loss: 1.4091 - val_accuracy: 0.5000\n",
      "Epoch 24/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.3851 - accuracy: 0.4926 - val_loss: 1.4397 - val_accuracy: 0.4760\n",
      "Epoch 25/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.3648 - accuracy: 0.5147 - val_loss: 1.4495 - val_accuracy: 0.4888\n",
      "Epoch 26/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.3607 - accuracy: 0.4974 - val_loss: 1.3923 - val_accuracy: 0.5272\n",
      "Epoch 27/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.3475 - accuracy: 0.5154 - val_loss: 1.4218 - val_accuracy: 0.5136\n",
      "Epoch 28/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.3581 - accuracy: 0.5102 - val_loss: 1.3076 - val_accuracy: 0.5401\n",
      "Epoch 29/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.3216 - accuracy: 0.5198 - val_loss: 1.3917 - val_accuracy: 0.5064\n",
      "Epoch 30/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.3392 - accuracy: 0.5154 - val_loss: 1.2500 - val_accuracy: 0.5665\n",
      "Epoch 31/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.2958 - accuracy: 0.5371 - val_loss: 1.5193 - val_accuracy: 0.5104\n",
      "Epoch 32/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.2903 - accuracy: 0.5331 - val_loss: 1.3096 - val_accuracy: 0.5497\n",
      "Epoch 33/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.2723 - accuracy: 0.5392 - val_loss: 1.3943 - val_accuracy: 0.5224\n",
      "Epoch 34/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.2985 - accuracy: 0.5355 - val_loss: 1.3119 - val_accuracy: 0.5264\n",
      "Epoch 35/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.2655 - accuracy: 0.5360 - val_loss: 1.2226 - val_accuracy: 0.5729\n",
      "Epoch 36/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.2771 - accuracy: 0.5383 - val_loss: 1.2380 - val_accuracy: 0.5745\n",
      "Epoch 37/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.2814 - accuracy: 0.5432 - val_loss: 1.4788 - val_accuracy: 0.5120\n",
      "Epoch 38/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.2538 - accuracy: 0.5490 - val_loss: 1.5122 - val_accuracy: 0.5256\n",
      "Epoch 39/300\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 1.2708 - accuracy: 0.5501 - val_loss: 1.3150 - val_accuracy: 0.5577\n",
      "Epoch 40/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.2556 - accuracy: 0.5522 - val_loss: 1.4810 - val_accuracy: 0.5377\n",
      "Epoch 41/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.2476 - accuracy: 0.5552 - val_loss: 1.4224 - val_accuracy: 0.5280\n",
      "Epoch 42/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.2368 - accuracy: 0.5464 - val_loss: 1.3413 - val_accuracy: 0.5441\n",
      "Epoch 43/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 1.2387 - accuracy: 0.5522 - val_loss: 1.1548 - val_accuracy: 0.5929\n",
      "Epoch 44/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.2259 - accuracy: 0.5576 - val_loss: 1.1184 - val_accuracy: 0.5970\n",
      "Epoch 45/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.2255 - accuracy: 0.5575 - val_loss: 1.1708 - val_accuracy: 0.5938\n",
      "Epoch 46/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1862 - accuracy: 0.5770 - val_loss: 1.1426 - val_accuracy: 0.5745\n",
      "Epoch 47/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1979 - accuracy: 0.5647 - val_loss: 1.2934 - val_accuracy: 0.55772s\n",
      "Epoch 48/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 1.2176 - accuracy: 0.5591 - val_loss: 1.1777 - val_accuracy: 0.5849\n",
      "Epoch 49/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.1699 - accuracy: 0.5810 - val_loss: 1.3215 - val_accuracy: 0.5601\n",
      "Epoch 50/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.2015 - accuracy: 0.5658 - val_loss: 1.3733 - val_accuracy: 0.5601\n",
      "Epoch 51/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1777 - accuracy: 0.5776 - val_loss: 1.3275 - val_accuracy: 0.5617\n",
      "Epoch 52/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.1925 - accuracy: 0.5672 - val_loss: 1.1273 - val_accuracy: 0.5994\n",
      "Epoch 53/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1813 - accuracy: 0.5717 - val_loss: 1.1050 - val_accuracy: 0.6050\n",
      "Epoch 54/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1669 - accuracy: 0.5751 - val_loss: 1.3155 - val_accuracy: 0.5785\n",
      "Epoch 55/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 1.1612 - accuracy: 0.5829 - val_loss: 1.1885 - val_accuracy: 0.5986\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 26s 33ms/step - loss: 1.1641 - accuracy: 0.5887 - val_loss: 1.2719 - val_accuracy: 0.5585\n",
      "Epoch 57/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1587 - accuracy: 0.5879 - val_loss: 1.3338 - val_accuracy: 0.5713\n",
      "Epoch 58/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1524 - accuracy: 0.5816 - val_loss: 1.1720 - val_accuracy: 0.5978\n",
      "Epoch 59/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.1310 - accuracy: 0.5972 - val_loss: 1.1640 - val_accuracy: 0.5881\n",
      "Epoch 60/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.1252 - accuracy: 0.5980 - val_loss: 1.2517 - val_accuracy: 0.5561\n",
      "Epoch 61/300\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 1.1438 - accuracy: 0.5909 - val_loss: 1.2336 - val_accuracy: 0.5873\n",
      "Epoch 62/300\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 1.1380 - accuracy: 0.5928 - val_loss: 1.2745 - val_accuracy: 0.5793\n",
      "Epoch 63/300\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 1.1449 - accuracy: 0.5906 - val_loss: 1.0232 - val_accuracy: 0.6402\n",
      "Epoch 64/300\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 1.1225 - accuracy: 0.5962 - val_loss: 1.0010 - val_accuracy: 0.6298\n",
      "Epoch 65/300\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 1.1245 - accuracy: 0.5962 - val_loss: 1.2423 - val_accuracy: 0.5946\n",
      "Epoch 66/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1333 - accuracy: 0.5988 - val_loss: 1.1775 - val_accuracy: 0.5970\n",
      "Epoch 67/300\n",
      "781/781 [==============================] - 25s 31ms/step - loss: 1.1261 - accuracy: 0.5973 - val_loss: 1.3525 - val_accuracy: 0.5609\n",
      "Epoch 68/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1216 - accuracy: 0.5919 - val_loss: 1.3168 - val_accuracy: 0.5545\n",
      "Epoch 69/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1297 - accuracy: 0.5978 - val_loss: 1.1017 - val_accuracy: 0.6162\n",
      "Epoch 70/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.1069 - accuracy: 0.5994 - val_loss: 1.1252 - val_accuracy: 0.6402\n",
      "Epoch 71/300\n",
      "781/781 [==============================] - 29s 37ms/step - loss: 1.1009 - accuracy: 0.6148 - val_loss: 1.1286 - val_accuracy: 0.6042\n",
      "Epoch 72/300\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 1.1171 - accuracy: 0.6061 - val_loss: 1.2067 - val_accuracy: 0.5986\n",
      "Epoch 73/300\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 1.1154 - accuracy: 0.5988 - val_loss: 1.1464 - val_accuracy: 0.5978\n",
      "Epoch 74/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.1090 - accuracy: 0.6079 - val_loss: 1.2083 - val_accuracy: 0.6026\n",
      "Epoch 75/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.1218 - accuracy: 0.6005 - val_loss: 1.0758 - val_accuracy: 0.6338\n",
      "Epoch 76/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0897 - accuracy: 0.6109 - val_loss: 1.0074 - val_accuracy: 0.6282\n",
      "Epoch 77/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0903 - accuracy: 0.6090 - val_loss: 1.0255 - val_accuracy: 0.6378\n",
      "Epoch 78/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0839 - accuracy: 0.6061 - val_loss: 1.0181 - val_accuracy: 0.6370\n",
      "Epoch 79/300\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 1.0816 - accuracy: 0.6125 - val_loss: 1.1982 - val_accuracy: 0.6010\n",
      "Epoch 80/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0752 - accuracy: 0.6152 - val_loss: 1.0760 - val_accuracy: 0.6370\n",
      "Epoch 81/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.1015 - accuracy: 0.5992 - val_loss: 1.0250 - val_accuracy: 0.6498\n",
      "Epoch 82/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0954 - accuracy: 0.6120 - val_loss: 1.0521 - val_accuracy: 0.6386\n",
      "Epoch 83/300\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 1.0858 - accuracy: 0.6100 - val_loss: 1.0169 - val_accuracy: 0.6330\n",
      "Epoch 84/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0491 - accuracy: 0.6296 - val_loss: 1.1691 - val_accuracy: 0.6074\n",
      "Epoch 85/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0789 - accuracy: 0.6144 - val_loss: 1.0107 - val_accuracy: 0.6514\n",
      "Epoch 86/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0675 - accuracy: 0.6231 - val_loss: 1.0731 - val_accuracy: 0.6330\n",
      "Epoch 87/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 1.0818 - accuracy: 0.6127 - val_loss: 1.1684 - val_accuracy: 0.6010\n",
      "Epoch 88/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0515 - accuracy: 0.6306 - val_loss: 1.0665 - val_accuracy: 0.6242\n",
      "Epoch 89/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0686 - accuracy: 0.6176 - val_loss: 1.2591 - val_accuracy: 0.5873\n",
      "Epoch 90/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0634 - accuracy: 0.6192 - val_loss: 1.0814 - val_accuracy: 0.6282\n",
      "Epoch 91/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0744 - accuracy: 0.6173 - val_loss: 0.9926 - val_accuracy: 0.6458\n",
      "Epoch 92/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 1.0463 - accuracy: 0.6308 - val_loss: 1.0299 - val_accuracy: 0.6474\n",
      "Epoch 93/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0394 - accuracy: 0.6320 - val_loss: 1.0456 - val_accuracy: 0.6402\n",
      "Epoch 94/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0454 - accuracy: 0.6324 - val_loss: 0.9639 - val_accuracy: 0.6514\n",
      "Epoch 95/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0390 - accuracy: 0.6330 - val_loss: 0.9191 - val_accuracy: 0.6587\n",
      "Epoch 96/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0463 - accuracy: 0.6248 - val_loss: 1.0776 - val_accuracy: 0.6210\n",
      "Epoch 97/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0206 - accuracy: 0.6407 - val_loss: 1.0196 - val_accuracy: 0.6466\n",
      "Epoch 98/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 1.0382 - accuracy: 0.6260 - val_loss: 0.9272 - val_accuracy: 0.6723\n",
      "Epoch 99/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0402 - accuracy: 0.6360 - val_loss: 1.0328 - val_accuracy: 0.6530\n",
      "Epoch 100/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0345 - accuracy: 0.6295 - val_loss: 1.0647 - val_accuracy: 0.6571\n",
      "Epoch 101/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0411 - accuracy: 0.6346 - val_loss: 1.1264 - val_accuracy: 0.6458\n",
      "Epoch 102/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0654 - accuracy: 0.6263 - val_loss: 1.1370 - val_accuracy: 0.6066\n",
      "Epoch 103/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0239 - accuracy: 0.6344 - val_loss: 1.2956 - val_accuracy: 0.5897\n",
      "Epoch 104/300\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 1.0297 - accuracy: 0.6372 - val_loss: 1.1797 - val_accuracy: 0.6106\n",
      "Epoch 105/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0336 - accuracy: 0.6384 - val_loss: 0.9748 - val_accuracy: 0.6554\n",
      "Epoch 106/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0326 - accuracy: 0.6292 - val_loss: 1.0070 - val_accuracy: 0.6434\n",
      "Epoch 107/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0148 - accuracy: 0.6397 - val_loss: 1.0121 - val_accuracy: 0.6530\n",
      "Epoch 108/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0278 - accuracy: 0.6370 - val_loss: 0.9340 - val_accuracy: 0.6683\n",
      "Epoch 109/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0197 - accuracy: 0.6346 - val_loss: 0.8789 - val_accuracy: 0.6771\n",
      "Epoch 110/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0233 - accuracy: 0.6378 - val_loss: 0.9266 - val_accuracy: 0.6843\n",
      "Epoch 111/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0064 - accuracy: 0.6356 - val_loss: 0.8879 - val_accuracy: 0.6811\n",
      "Epoch 112/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 26s 34ms/step - loss: 0.9912 - accuracy: 0.6458 - val_loss: 1.1564 - val_accuracy: 0.6082\n",
      "Epoch 113/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0070 - accuracy: 0.6464 - val_loss: 0.9709 - val_accuracy: 0.6458\n",
      "Epoch 114/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0299 - accuracy: 0.6308 - val_loss: 0.9557 - val_accuracy: 0.6619\n",
      "Epoch 115/300\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 1.0149 - accuracy: 0.6420 - val_loss: 0.8962 - val_accuracy: 0.6995\n",
      "Epoch 116/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0147 - accuracy: 0.6434 - val_loss: 0.8634 - val_accuracy: 0.6995\n",
      "Epoch 117/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0026 - accuracy: 0.6412 - val_loss: 0.9113 - val_accuracy: 0.6747\n",
      "Epoch 118/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0005 - accuracy: 0.6436 - val_loss: 1.0456 - val_accuracy: 0.6466\n",
      "Epoch 119/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0212 - accuracy: 0.6309 - val_loss: 1.0285 - val_accuracy: 0.6498\n",
      "Epoch 120/300\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 1.0068 - accuracy: 0.6432 - val_loss: 0.8856 - val_accuracy: 0.6835\n",
      "Epoch 121/300\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.9803 - accuracy: 0.6512 - val_loss: 0.9624 - val_accuracy: 0.6506\n",
      "Epoch 122/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0172 - accuracy: 0.6396 - val_loss: 1.0008 - val_accuracy: 0.6458\n",
      "Epoch 123/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9897 - accuracy: 0.6524 - val_loss: 0.9045 - val_accuracy: 0.6851\n",
      "Epoch 124/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 1.0239 - accuracy: 0.6325 - val_loss: 0.8014 - val_accuracy: 0.7043\n",
      "Epoch 125/300\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 1.0071 - accuracy: 0.6400 - val_loss: 1.1531 - val_accuracy: 0.6122\n",
      "Epoch 126/300\n",
      "781/781 [==============================] - 31s 39ms/step - loss: 1.0153 - accuracy: 0.6362 - val_loss: 1.0322 - val_accuracy: 0.6755\n",
      "Epoch 127/300\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.9951 - accuracy: 0.6436 - val_loss: 0.9337 - val_accuracy: 0.6779\n",
      "Epoch 128/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 1.0068 - accuracy: 0.6468 - val_loss: 0.8853 - val_accuracy: 0.6819\n",
      "Epoch 129/300\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.9883 - accuracy: 0.6535 - val_loss: 0.8968 - val_accuracy: 0.6899\n",
      "Epoch 130/300\n",
      "781/781 [==============================] - 32s 41ms/step - loss: 0.9792 - accuracy: 0.6533 - val_loss: 1.0434 - val_accuracy: 0.6587\n",
      "Epoch 131/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9779 - accuracy: 0.6543 - val_loss: 0.9011 - val_accuracy: 0.6803\n",
      "Epoch 132/300\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.9850 - accuracy: 0.6530 - val_loss: 0.9704 - val_accuracy: 0.6771\n",
      "Epoch 133/300\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.9905 - accuracy: 0.6442 - val_loss: 1.0242 - val_accuracy: 0.6546\n",
      "Epoch 134/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9924 - accuracy: 0.6455 - val_loss: 0.8749 - val_accuracy: 0.6811\n",
      "Epoch 135/300\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 0.9721 - accuracy: 0.6599 - val_loss: 0.8683 - val_accuracy: 0.7003\n",
      "Epoch 136/300\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.9776 - accuracy: 0.6609 - val_loss: 0.9687 - val_accuracy: 0.6571\n",
      "Epoch 137/300\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.9647 - accuracy: 0.6650 - val_loss: 0.8856 - val_accuracy: 0.6923\n",
      "Epoch 138/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9793 - accuracy: 0.6522 - val_loss: 0.9431 - val_accuracy: 0.6715\n",
      "Epoch 139/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9937 - accuracy: 0.6463 - val_loss: 0.8740 - val_accuracy: 0.7027\n",
      "Epoch 140/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9733 - accuracy: 0.6554 - val_loss: 0.8960 - val_accuracy: 0.6835\n",
      "Epoch 141/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.9608 - accuracy: 0.6644 - val_loss: 0.9785 - val_accuracy: 0.6595\n",
      "Epoch 142/300\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 0.9718 - accuracy: 0.6578 - val_loss: 0.9259 - val_accuracy: 0.6819\n",
      "Epoch 143/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9949 - accuracy: 0.6488 - val_loss: 0.9711 - val_accuracy: 0.6619\n",
      "Epoch 144/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9701 - accuracy: 0.6508 - val_loss: 1.1516 - val_accuracy: 0.6306\n",
      "Epoch 145/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9550 - accuracy: 0.6636 - val_loss: 0.9762 - val_accuracy: 0.6763\n",
      "Epoch 146/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9817 - accuracy: 0.6482 - val_loss: 0.8410 - val_accuracy: 0.6987\n",
      "Epoch 147/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9750 - accuracy: 0.6541 - val_loss: 0.8959 - val_accuracy: 0.6827\n",
      "Epoch 148/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.9516 - accuracy: 0.6663 - val_loss: 0.9462 - val_accuracy: 0.6747\n",
      "Epoch 149/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9690 - accuracy: 0.6583 - val_loss: 0.8406 - val_accuracy: 0.7115\n",
      "Epoch 150/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9594 - accuracy: 0.6575 - val_loss: 0.8508 - val_accuracy: 0.7163\n",
      "Epoch 151/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9496 - accuracy: 0.6724 - val_loss: 0.9312 - val_accuracy: 0.6779\n",
      "Epoch 152/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9284 - accuracy: 0.6796 - val_loss: 0.9297 - val_accuracy: 0.6827\n",
      "Epoch 153/300\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.9537 - accuracy: 0.6613 - val_loss: 0.9152 - val_accuracy: 0.7067\n",
      "Epoch 154/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9349 - accuracy: 0.6642 - val_loss: 0.8358 - val_accuracy: 0.7075\n",
      "Epoch 155/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9783 - accuracy: 0.6509 - val_loss: 0.9215 - val_accuracy: 0.6851\n",
      "Epoch 156/300\n",
      "781/781 [==============================] - 26s 34ms/step - loss: 0.9553 - accuracy: 0.6588 - val_loss: 0.7868 - val_accuracy: 0.7292\n",
      "Epoch 157/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9530 - accuracy: 0.6631 - val_loss: 0.9568 - val_accuracy: 0.6779\n",
      "Epoch 158/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9319 - accuracy: 0.6738 - val_loss: 0.9666 - val_accuracy: 0.6683\n",
      "Epoch 159/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9447 - accuracy: 0.6689 - val_loss: 0.9192 - val_accuracy: 0.6787\n",
      "Epoch 160/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9405 - accuracy: 0.6700 - val_loss: 1.0594 - val_accuracy: 0.6450\n",
      "Epoch 161/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9457 - accuracy: 0.6655 - val_loss: 1.0013 - val_accuracy: 0.6603\n",
      "Epoch 162/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9519 - accuracy: 0.6629 - val_loss: 0.9339 - val_accuracy: 0.6931\n",
      "Epoch 163/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9366 - accuracy: 0.6724 - val_loss: 1.0841 - val_accuracy: 0.6434\n",
      "Epoch 164/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9760 - accuracy: 0.6552 - val_loss: 0.7807 - val_accuracy: 0.7035\n",
      "Epoch 165/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9498 - accuracy: 0.6631 - val_loss: 1.0795 - val_accuracy: 0.6667\n",
      "Epoch 166/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9275 - accuracy: 0.6754 - val_loss: 1.1134 - val_accuracy: 0.6346\n",
      "Epoch 167/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9390 - accuracy: 0.6738 - val_loss: 0.9352 - val_accuracy: 0.6891\n",
      "Epoch 168/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9477 - accuracy: 0.6697 - val_loss: 0.9238 - val_accuracy: 0.6875\n",
      "Epoch 169/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.9443 - accuracy: 0.6649 - val_loss: 1.0909 - val_accuracy: 0.6426\n",
      "Epoch 170/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9387 - accuracy: 0.6681 - val_loss: 0.8553 - val_accuracy: 0.6971\n",
      "Epoch 171/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9356 - accuracy: 0.6757 - val_loss: 0.8096 - val_accuracy: 0.7179\n",
      "Epoch 172/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9375 - accuracy: 0.6713 - val_loss: 0.8890 - val_accuracy: 0.6883\n",
      "Epoch 173/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9307 - accuracy: 0.6647 - val_loss: 1.0499 - val_accuracy: 0.6482\n",
      "Epoch 174/300\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 0.9258 - accuracy: 0.6716 - val_loss: 1.0622 - val_accuracy: 0.6418\n",
      "Epoch 175/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9474 - accuracy: 0.6572 - val_loss: 0.9109 - val_accuracy: 0.6827\n",
      "Epoch 176/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9499 - accuracy: 0.6565 - val_loss: 0.9405 - val_accuracy: 0.6811\n",
      "Epoch 177/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9246 - accuracy: 0.6698 - val_loss: 1.0544 - val_accuracy: 0.6410\n",
      "Epoch 178/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.9392 - accuracy: 0.6681 - val_loss: 0.9153 - val_accuracy: 0.6803\n",
      "Epoch 179/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9117 - accuracy: 0.6802 - val_loss: 0.8653 - val_accuracy: 0.7083\n",
      "Epoch 180/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.9125 - accuracy: 0.6770 - val_loss: 1.0909 - val_accuracy: 0.6290\n",
      "Epoch 181/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9158 - accuracy: 0.6757 - val_loss: 0.8024 - val_accuracy: 0.7139\n",
      "Epoch 182/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9122 - accuracy: 0.6812 - val_loss: 0.8621 - val_accuracy: 0.6907\n",
      "Epoch 183/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9173 - accuracy: 0.6759 - val_loss: 0.8514 - val_accuracy: 0.7139\n",
      "Epoch 184/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9199 - accuracy: 0.6751 - val_loss: 0.8890 - val_accuracy: 0.6891\n",
      "Epoch 185/300\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 0.9054 - accuracy: 0.6761 - val_loss: 0.8434 - val_accuracy: 0.6955\n",
      "Epoch 186/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9160 - accuracy: 0.6781 - val_loss: 0.9535 - val_accuracy: 0.6883\n",
      "Epoch 187/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9319 - accuracy: 0.6709 - val_loss: 0.9254 - val_accuracy: 0.6931\n",
      "Epoch 188/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9121 - accuracy: 0.6780 - val_loss: 0.9739 - val_accuracy: 0.6755\n",
      "Epoch 189/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9189 - accuracy: 0.6834 - val_loss: 1.0672 - val_accuracy: 0.6490\n",
      "Epoch 190/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9334 - accuracy: 0.6687 - val_loss: 0.8303 - val_accuracy: 0.7091\n",
      "Epoch 191/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.9057 - accuracy: 0.6855 - val_loss: 1.0689 - val_accuracy: 0.6338\n",
      "Epoch 192/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9150 - accuracy: 0.6809 - val_loss: 0.9407 - val_accuracy: 0.6907\n",
      "Epoch 193/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9201 - accuracy: 0.6749 - val_loss: 1.1306 - val_accuracy: 0.6162\n",
      "Epoch 194/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9110 - accuracy: 0.6825 - val_loss: 0.8818 - val_accuracy: 0.6955\n",
      "Epoch 195/300\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.9008 - accuracy: 0.6829 - val_loss: 1.0103 - val_accuracy: 0.6619\n",
      "Epoch 196/300\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 0.9226 - accuracy: 0.6725 - val_loss: 0.8161 - val_accuracy: 0.7131\n",
      "Epoch 197/300\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 0.9125 - accuracy: 0.6797 - val_loss: 0.9806 - val_accuracy: 0.6731\n",
      "Epoch 198/300\n",
      "781/781 [==============================] - 28s 36ms/step - loss: 0.8941 - accuracy: 0.6797 - val_loss: 0.8465 - val_accuracy: 0.7171\n",
      "Epoch 199/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9022 - accuracy: 0.6807 - val_loss: 0.8256 - val_accuracy: 0.7067\n",
      "Epoch 200/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9192 - accuracy: 0.6783 - val_loss: 0.8054 - val_accuracy: 0.7043\n",
      "Epoch 201/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8959 - accuracy: 0.6842 - val_loss: 0.7737 - val_accuracy: 0.7220\n",
      "Epoch 202/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8849 - accuracy: 0.6852 - val_loss: 0.8160 - val_accuracy: 0.7244\n",
      "Epoch 203/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9084 - accuracy: 0.6809 - val_loss: 0.8701 - val_accuracy: 0.7051\n",
      "Epoch 204/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9157 - accuracy: 0.6821 - val_loss: 0.7602 - val_accuracy: 0.7340\n",
      "Epoch 205/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9049 - accuracy: 0.6769 - val_loss: 1.0204 - val_accuracy: 0.6554\n",
      "Epoch 206/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9045 - accuracy: 0.6797 - val_loss: 0.8479 - val_accuracy: 0.7139\n",
      "Epoch 207/300\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 0.9120 - accuracy: 0.6748 - val_loss: 0.8269 - val_accuracy: 0.7115\n",
      "Epoch 208/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9212 - accuracy: 0.6751 - val_loss: 0.8005 - val_accuracy: 0.7204\n",
      "Epoch 209/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9102 - accuracy: 0.6858 - val_loss: 0.8714 - val_accuracy: 0.6939\n",
      "Epoch 210/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8916 - accuracy: 0.6810 - val_loss: 0.8361 - val_accuracy: 0.7276\n",
      "Epoch 211/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.8860 - accuracy: 0.6898 - val_loss: 0.7923 - val_accuracy: 0.7244\n",
      "Epoch 212/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9022 - accuracy: 0.6719 - val_loss: 0.7249 - val_accuracy: 0.7684\n",
      "Epoch 213/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8911 - accuracy: 0.6858 - val_loss: 0.8948 - val_accuracy: 0.6875\n",
      "Epoch 214/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9220 - accuracy: 0.6716 - val_loss: 1.0083 - val_accuracy: 0.6683\n",
      "Epoch 215/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.8921 - accuracy: 0.6898 - val_loss: 0.8261 - val_accuracy: 0.7035\n",
      "Epoch 216/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8940 - accuracy: 0.6825 - val_loss: 0.9092 - val_accuracy: 0.6923\n",
      "Epoch 217/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8983 - accuracy: 0.6801 - val_loss: 0.8560 - val_accuracy: 0.6955\n",
      "Epoch 218/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.8885 - accuracy: 0.6925 - val_loss: 0.8622 - val_accuracy: 0.7139\n",
      "Epoch 219/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8878 - accuracy: 0.6855 - val_loss: 0.8491 - val_accuracy: 0.6915\n",
      "Epoch 220/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.8910 - accuracy: 0.6805 - val_loss: 0.8964 - val_accuracy: 0.6923\n",
      "Epoch 221/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.9134 - accuracy: 0.6777 - val_loss: 0.9527 - val_accuracy: 0.6619\n",
      "Epoch 222/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 25s 33ms/step - loss: 0.8993 - accuracy: 0.6906 - val_loss: 0.8451 - val_accuracy: 0.7051\n",
      "Epoch 223/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8810 - accuracy: 0.6911 - val_loss: 0.8755 - val_accuracy: 0.6987\n",
      "Epoch 224/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8865 - accuracy: 0.6905 - val_loss: 0.8360 - val_accuracy: 0.7035\n",
      "Epoch 225/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8942 - accuracy: 0.6834 - val_loss: 0.7836 - val_accuracy: 0.7204\n",
      "Epoch 226/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8928 - accuracy: 0.6938 - val_loss: 0.9551 - val_accuracy: 0.6843\n",
      "Epoch 227/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9093 - accuracy: 0.6786 - val_loss: 0.8778 - val_accuracy: 0.7067\n",
      "Epoch 228/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9016 - accuracy: 0.6777 - val_loss: 0.8801 - val_accuracy: 0.7067\n",
      "Epoch 229/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8946 - accuracy: 0.6844 - val_loss: 0.8331 - val_accuracy: 0.7188\n",
      "Epoch 230/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8501 - accuracy: 0.7041 - val_loss: 0.8268 - val_accuracy: 0.7179\n",
      "Epoch 231/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8765 - accuracy: 0.6879 - val_loss: 0.7815 - val_accuracy: 0.7252\n",
      "Epoch 232/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8815 - accuracy: 0.6911 - val_loss: 0.8496 - val_accuracy: 0.7163\n",
      "Epoch 233/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8809 - accuracy: 0.6895 - val_loss: 0.9003 - val_accuracy: 0.6971\n",
      "Epoch 234/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9051 - accuracy: 0.6813 - val_loss: 0.8618 - val_accuracy: 0.7252\n",
      "Epoch 235/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8720 - accuracy: 0.6941 - val_loss: 0.9496 - val_accuracy: 0.6771\n",
      "Epoch 236/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8786 - accuracy: 0.6922 - val_loss: 0.7421 - val_accuracy: 0.7188\n",
      "Epoch 237/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8842 - accuracy: 0.6914 - val_loss: 0.7999 - val_accuracy: 0.7204\n",
      "Epoch 238/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8907 - accuracy: 0.6885 - val_loss: 0.8751 - val_accuracy: 0.6819\n",
      "Epoch 239/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8656 - accuracy: 0.6900 - val_loss: 0.8085 - val_accuracy: 0.7051\n",
      "Epoch 240/300\n",
      "781/781 [==============================] - 25s 31ms/step - loss: 0.8684 - accuracy: 0.6972 - val_loss: 0.8738 - val_accuracy: 0.7067\n",
      "Epoch 241/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8866 - accuracy: 0.6884 - val_loss: 0.7662 - val_accuracy: 0.7316\n",
      "Epoch 242/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8931 - accuracy: 0.6871 - val_loss: 0.8075 - val_accuracy: 0.7147\n",
      "Epoch 243/300\n",
      "781/781 [==============================] - 25s 31ms/step - loss: 0.8923 - accuracy: 0.6828 - val_loss: 0.8288 - val_accuracy: 0.7163\n",
      "Epoch 244/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8781 - accuracy: 0.6887 - val_loss: 0.7912 - val_accuracy: 0.7155\n",
      "Epoch 245/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8766 - accuracy: 0.6978 - val_loss: 0.8854 - val_accuracy: 0.6899\n",
      "Epoch 246/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8740 - accuracy: 0.6941 - val_loss: 0.9091 - val_accuracy: 0.6795\n",
      "Epoch 247/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8901 - accuracy: 0.6877 - val_loss: 0.8026 - val_accuracy: 0.7308\n",
      "Epoch 248/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8650 - accuracy: 0.6948 - val_loss: 0.9454 - val_accuracy: 0.6731\n",
      "Epoch 249/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.8821 - accuracy: 0.6842 - val_loss: 0.9929 - val_accuracy: 0.6819\n",
      "Epoch 250/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9054 - accuracy: 0.6788 - val_loss: 0.8316 - val_accuracy: 0.7043\n",
      "Epoch 251/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8801 - accuracy: 0.6953 - val_loss: 0.8114 - val_accuracy: 0.7188\n",
      "Epoch 252/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8841 - accuracy: 0.6813 - val_loss: 0.9439 - val_accuracy: 0.6923\n",
      "Epoch 253/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8658 - accuracy: 0.6954 - val_loss: 0.8592 - val_accuracy: 0.7027\n",
      "Epoch 254/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8687 - accuracy: 0.6967 - val_loss: 0.7933 - val_accuracy: 0.7147\n",
      "Epoch 255/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8638 - accuracy: 0.6978 - val_loss: 0.7835 - val_accuracy: 0.7163\n",
      "Epoch 256/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8707 - accuracy: 0.6983 - val_loss: 0.7862 - val_accuracy: 0.7212\n",
      "Epoch 257/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8752 - accuracy: 0.6927 - val_loss: 0.8659 - val_accuracy: 0.7091\n",
      "Epoch 258/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8850 - accuracy: 0.6884 - val_loss: 0.8031 - val_accuracy: 0.7188\n",
      "Epoch 259/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.8647 - accuracy: 0.6988 - val_loss: 0.8203 - val_accuracy: 0.7316\n",
      "Epoch 260/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8620 - accuracy: 0.7009 - val_loss: 0.8017 - val_accuracy: 0.7196\n",
      "Epoch 261/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8651 - accuracy: 0.6994 - val_loss: 0.9776 - val_accuracy: 0.6835\n",
      "Epoch 262/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8527 - accuracy: 0.7010 - val_loss: 0.8245 - val_accuracy: 0.7107\n",
      "Epoch 263/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8402 - accuracy: 0.7090 - val_loss: 0.9133 - val_accuracy: 0.6907\n",
      "Epoch 264/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8797 - accuracy: 0.6922 - val_loss: 0.7833 - val_accuracy: 0.7268\n",
      "Epoch 265/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8373 - accuracy: 0.7026 - val_loss: 0.7857 - val_accuracy: 0.7404\n",
      "Epoch 266/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8682 - accuracy: 0.6959 - val_loss: 0.7662 - val_accuracy: 0.7396\n",
      "Epoch 267/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8563 - accuracy: 0.6977 - val_loss: 0.7710 - val_accuracy: 0.7292\n",
      "Epoch 268/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8487 - accuracy: 0.6991 - val_loss: 0.9055 - val_accuracy: 0.6915\n",
      "Epoch 269/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8545 - accuracy: 0.6978 - val_loss: 0.8665 - val_accuracy: 0.7123\n",
      "Epoch 270/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8553 - accuracy: 0.7065 - val_loss: 0.7714 - val_accuracy: 0.7412\n",
      "Epoch 271/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8545 - accuracy: 0.6956 - val_loss: 0.9304 - val_accuracy: 0.6875\n",
      "Epoch 272/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8536 - accuracy: 0.7053 - val_loss: 0.9125 - val_accuracy: 0.6955\n",
      "Epoch 273/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8462 - accuracy: 0.7009 - val_loss: 0.7930 - val_accuracy: 0.7123\n",
      "Epoch 274/300\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8662 - accuracy: 0.6956 - val_loss: 0.7586 - val_accuracy: 0.7372\n",
      "Epoch 275/300\n",
      "781/781 [==============================] - 27s 35ms/step - loss: 0.8735 - accuracy: 0.6927 - val_loss: 0.7688 - val_accuracy: 0.7468\n",
      "Epoch 276/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8521 - accuracy: 0.7031 - val_loss: 0.7532 - val_accuracy: 0.7428\n",
      "Epoch 277/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8736 - accuracy: 0.6972 - val_loss: 0.8645 - val_accuracy: 0.7043\n",
      "Epoch 278/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8444 - accuracy: 0.7095 - val_loss: 0.9008 - val_accuracy: 0.7067\n",
      "Epoch 279/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8663 - accuracy: 0.6921 - val_loss: 0.7136 - val_accuracy: 0.7436\n",
      "Epoch 280/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8552 - accuracy: 0.6994 - val_loss: 0.7412 - val_accuracy: 0.7548\n",
      "Epoch 281/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8682 - accuracy: 0.6932 - val_loss: 0.7555 - val_accuracy: 0.7380\n",
      "Epoch 282/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8761 - accuracy: 0.6930 - val_loss: 0.7008 - val_accuracy: 0.7508\n",
      "Epoch 283/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8746 - accuracy: 0.6930 - val_loss: 0.9014 - val_accuracy: 0.6995\n",
      "Epoch 284/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8486 - accuracy: 0.7020 - val_loss: 0.8124 - val_accuracy: 0.7196\n",
      "Epoch 285/300\n",
      "781/781 [==============================] - 26s 33ms/step - loss: 0.8555 - accuracy: 0.7020 - val_loss: 0.7650 - val_accuracy: 0.7452\n",
      "Epoch 286/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8286 - accuracy: 0.7113 - val_loss: 0.7688 - val_accuracy: 0.7380s: 0.8\n",
      "Epoch 287/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8659 - accuracy: 0.6964 - val_loss: 0.7168 - val_accuracy: 0.7540\n",
      "Epoch 288/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8545 - accuracy: 0.6988 - val_loss: 0.9409 - val_accuracy: 0.6939\n",
      "Epoch 289/300\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 0.8393 - accuracy: 0.7073 - val_loss: 0.9542 - val_accuracy: 0.6891\n",
      "Epoch 290/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.8519 - accuracy: 0.6959 - val_loss: 0.7072 - val_accuracy: 0.74760s - loss: 0.8457 - ac - ETA: 0s - loss: 0.8473 - accura\n",
      "Epoch 291/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8528 - accuracy: 0.7013 - val_loss: 0.6974 - val_accuracy: 0.7532\n",
      "Epoch 292/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.8656 - accuracy: 0.7018 - val_loss: 0.9891 - val_accuracy: 0.6723\n",
      "Epoch 293/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8608 - accuracy: 0.6919 - val_loss: 0.7156 - val_accuracy: 0.7404\n",
      "Epoch 294/300\n",
      "781/781 [==============================] - 25s 31ms/step - loss: 0.8370 - accuracy: 0.7049 - val_loss: 0.8346 - val_accuracy: 0.7163\n",
      "Epoch 295/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8775 - accuracy: 0.6929 - val_loss: 0.6576 - val_accuracy: 0.7700\n",
      "Epoch 296/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8504 - accuracy: 0.7073 - val_loss: 0.8601 - val_accuracy: 0.7212\n",
      "Epoch 297/300\n",
      "781/781 [==============================] - 25s 33ms/step - loss: 0.8438 - accuracy: 0.7050 - val_loss: 0.6869 - val_accuracy: 0.7564\n",
      "Epoch 298/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8411 - accuracy: 0.6983 - val_loss: 0.7862 - val_accuracy: 0.7252\n",
      "Epoch 299/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8357 - accuracy: 0.7063 - val_loss: 0.7732 - val_accuracy: 0.7268\n",
      "Epoch 300/300\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8546 - accuracy: 0.6989 - val_loss: 0.7247 - val_accuracy: 0.7484\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.8399 - accuracy: 0.7342\n",
      "Test loss: 0.839928388595581\n",
      "Test accuracy: 0.7342000007629395\n",
      "Saved model to disk\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "dense_model_1(X_train, y_train, X_test, y_test, batch_size, step_size, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap-tel__t-5X"
   },
   "source": [
    "## Model DENSENET-BOTTLENECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "47OoqbgwuaTy"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "num_classes = 10\n",
    "epochs =300\n",
    "step_size =64\n",
    "l = 12\n",
    "num_filter = 12\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1LxlN-4YtDYo"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_5_5 = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "        Conv2D_5_5 = layers.Conv2D(int(num_filter*compression), (5,5), use_bias=False ,padding='same')(Conv2D_5_5)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_5_5 = layers.Dropout(dropout_rate)(Conv2D_5_5)\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_5_5])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Blosck\n",
    "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SRbrxAxau9h4"
   },
   "outputs": [],
   "source": [
    "def dense_model(input_shape = (32,32,3), n_classes = 10):\n",
    "    X_input = Input(shape=(img_height, img_width, channel))\n",
    "    First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(X_input)\n",
    "    \n",
    "    First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "    First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "    Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "    Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "    Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "    Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "    Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "    output = output_layer(Last_Block)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7zKzNCpxNrb",
    "outputId": "9e06e0fb-dfff-4264-a754-8fce2c442af9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 12)   324         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 12)   48          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 12)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 6)    72          activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 6)    900         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 6)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 18)   0           conv2d[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 18)   72          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 18)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 6)    108         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 6)    900         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 6)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 24)   0           concatenate[0][0]                \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 24)   96          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 24)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 6)    144         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 6)    900         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 6)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 30)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 30)   120         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 30)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 6)    180         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 6)    900         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 6)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 36)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 36)   144         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 36)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 6)    216         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 6)    900         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 6)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 42)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 42)   168         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 42)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 6)    252         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 6)    900         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 6)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 48)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 6)    288         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 6)    900         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 6)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 54)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 54)   216         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 54)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 6)    324         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 6)    900         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 6)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 60)   0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 60)   240         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 60)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 6)    360         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 6)    900         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 6)    0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 66)   0           concatenate_7[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 66)   264         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 66)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 6)    396         activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 6)    900         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 6)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 72)   0           concatenate_8[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 72)   288         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 72)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 6)    432         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 6)    900         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 6)    0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 78)   0           concatenate_9[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 78)   312         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 78)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 6)    468         activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 6)    900         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 6)    0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 84)   0           concatenate_10[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 84)   336         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 84)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 6)    504         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 6)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 6)    0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 6)    24          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 6)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 6)    36          activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 6)    900         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 6)    0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 12)   0           average_pooling2d[0][0]          \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 12)   48          concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 12)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 6)    72          activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 6)    900         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 6)    0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 18)   0           concatenate_12[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 18)   72          concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 18)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 6)    108         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 6)    900         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 6)    0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 24)   0           concatenate_13[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 24)   96          concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 24)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 6)    144         activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 6)    900         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 6)    0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 30)   0           concatenate_14[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 30)   120         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 30)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 6)    180         activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 6)    900         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 6)    0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 36)   0           concatenate_15[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 36)   144         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 36)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 6)    216         activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 6)    900         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 6)    0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 42)   0           concatenate_16[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 42)   168         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 42)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 6)    252         activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 6)    900         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 6)    0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 48)   0           concatenate_17[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   192         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 6)    288         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 6)    900         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 6)    0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 54)   0           concatenate_18[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 54)   216         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 54)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 6)    324         activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 6)    900         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 6)    0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 60)   0           concatenate_19[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 60)   240         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 60)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 6)    360         activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 6)    900         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 6)    0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 66)   0           concatenate_20[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 66)   264         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 66)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 6)    396         activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 6)    900         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 6)    0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 72)   0           concatenate_21[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 72)   288         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 72)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 6)    432         activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 6)    900         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 6)    0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 78)   0           concatenate_22[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 78)   312         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 78)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 6)    468         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 6)    0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 6)      0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 6)      24          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 6)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 6)      36          activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 6)      900         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 6)      0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 12)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 12)     48          concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 12)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 6)      72          activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 6)      900         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 8, 8, 6)      0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 18)     0           concatenate_24[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 18)     72          concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 18)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 6)      108         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 6)      900         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 8, 8, 6)      0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 24)     0           concatenate_25[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 24)     96          concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 24)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 6)      144         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 6)      900         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 8, 8, 6)      0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 30)     0           concatenate_26[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 30)     120         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 30)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 6)      180         activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 6)      900         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 8, 8, 6)      0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 36)     0           concatenate_27[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 36)     144         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 36)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 6)      216         activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 6)      900         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 8, 8, 6)      0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 42)     0           concatenate_28[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 42)     168         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 42)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 6)      252         activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 6)      900         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 8, 8, 6)      0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 48)     0           concatenate_29[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 48)     192         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 8, 48)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 6)      288         activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 6)      900         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 8, 8, 6)      0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 54)     0           concatenate_30[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 54)     216         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 8, 54)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 6)      324         activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 6)      900         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 8, 8, 6)      0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 60)     0           concatenate_31[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 60)     240         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 60)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 6)      360         activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 6)      900         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 8, 8, 6)      0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 66)     0           concatenate_32[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 66)     264         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 66)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 6)      396         activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 6)      900         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 8, 8, 6)      0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 72)     0           concatenate_33[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 72)     288         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 72)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 6)      432         activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 6)      900         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 8, 8, 6)      0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 78)     0           concatenate_34[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 78)     312         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 78)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 6)      468         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 8, 8, 6)      0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 6)      0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 4, 4, 6)      24          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 6)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 4, 4, 6)      36          activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 4, 4, 6)      900         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 4, 4, 6)      0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 4, 4, 12)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 4, 4, 12)     48          concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 12)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 4, 4, 6)      72          activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 4, 4, 6)      900         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 4, 4, 6)      0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 4, 4, 18)     0           concatenate_36[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 4, 4, 18)     72          concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 18)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 4, 4, 6)      108         activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 4, 4, 6)      900         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 4, 4, 6)      0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 4, 4, 24)     0           concatenate_37[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 4, 4, 24)     96          concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 24)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 4, 4, 6)      144         activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 4, 4, 6)      900         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 4, 4, 6)      0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 4, 4, 30)     0           concatenate_38[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 4, 4, 30)     120         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 30)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 4, 4, 6)      180         activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 4, 4, 6)      900         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 4, 4, 6)      0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 4, 4, 36)     0           concatenate_39[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 4, 4, 36)     144         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 36)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 4, 4, 6)      216         activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 4, 4, 6)      900         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 4, 4, 6)      0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 4, 4, 42)     0           concatenate_40[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 4, 4, 42)     168         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 4, 4, 42)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 4, 4, 6)      252         activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 4, 4, 6)      900         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 4, 4, 6)      0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 4, 4, 48)     0           concatenate_41[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 4, 4, 48)     192         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 4, 4, 48)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 4, 4, 6)      288         activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 4, 4, 6)      900         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 4, 4, 6)      0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 54)     0           concatenate_42[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 4, 4, 54)     216         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 4, 4, 54)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 4, 4, 6)      324         activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 6)      900         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 4, 4, 6)      0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 60)     0           concatenate_43[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 4, 4, 60)     240         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 4, 4, 60)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 4, 4, 6)      360         activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 4, 4, 6)      900         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 4, 4, 6)      0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 66)     0           concatenate_44[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 4, 4, 66)     264         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 4, 4, 66)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 4, 6)      396         activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 4, 6)      900         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 4, 4, 6)      0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 72)     0           concatenate_45[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 4, 72)     288         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 4, 4, 72)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 4, 6)      432         activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 4, 6)      900         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 4, 4, 6)      0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 78)     0           concatenate_46[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 4, 78)     312         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 4, 4, 78)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 78)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 312)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           3130        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 68,806\n",
      "Trainable params: 64,282\n",
      "Non-trainable params: 4,524\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = dense_model(input_shape = (32,32,3), n_classes = 10)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOGm55gKxYaJ",
    "outputId": "d90294c9-2212-4592-dd3f-63cc78961658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n"
     ]
    }
   ],
   "source": [
    "print(len(model_2.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "U_4Z8TCgyGi6"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7ySGy6Y_wOwU"
   },
   "outputs": [],
   "source": [
    "def dense_model_2(X_train, y_train, X_test, y_test, batch_size, step_size, epochs):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10, # rotation\n",
    "        width_shift_range=0.2, # horizontal shift\n",
    "        height_shift_range=0.2, # vertical shift\n",
    "        zoom_range=0.2, # zoom\n",
    "        horizontal_flip=True, # horizontal flip\n",
    "        )\n",
    "    train_data = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "    test_data  = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "    # train_steps = train_data.samples // batch_size\n",
    "    # val_steps = test_data.samples // batch_size\n",
    "    train_steps = int(X_train.shape[0] / step_size)\n",
    "    val_steps = int(X_test.shape[0] / step_size)\n",
    "    history = model_2.fit(train_data, epochs=epochs,steps_per_epoch=train_steps,\n",
    "                              validation_data=test_data,validation_steps=val_steps)\n",
    "    # Test the model\n",
    "    score = model_2.evaluate(X_test, y_test, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Save the trained weights in to .h5 format\n",
    "    model_2.save_weights(\"DNST_bettleneck.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "    loss_train = history.history['accuracy']\n",
    "    loss_val = history.history['val_accuracy']\n",
    "    epochs = range(epochs)\n",
    "    plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "    plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy of DENSENET-BC\")\n",
    "    plt.show()\n",
    "\n",
    "    tf.keras.utils.plot_model(model_2, to_file='model_with_bc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "njkCkqJg43bw",
    "outputId": "9c576963-10ad-413f-db84-777960ce5315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "781/781 [==============================] - 100s 128ms/step - loss: 2.1517 - accuracy: 0.1933 - val_loss: 2.0410 - val_accuracy: 0.2516\n",
      "Epoch 2/300\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 1.9804 - accuracy: 0.2508 - val_loss: 1.8423 - val_accuracy: 0.3053\n",
      "Epoch 3/300\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 1.8811 - accuracy: 0.2926 - val_loss: 1.8185 - val_accuracy: 0.3221\n",
      "Epoch 4/300\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.8213 - accuracy: 0.3108 - val_loss: 1.8282 - val_accuracy: 0.3301\n",
      "Epoch 5/300\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.7800 - accuracy: 0.3422 - val_loss: 1.7285 - val_accuracy: 0.3774\n",
      "Epoch 6/300\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.7381 - accuracy: 0.3526 - val_loss: 1.7624 - val_accuracy: 0.3694\n",
      "Epoch 7/300\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.7071 - accuracy: 0.3662 - val_loss: 1.6604 - val_accuracy: 0.3878\n",
      "Epoch 8/300\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.6827 - accuracy: 0.3798 - val_loss: 1.6061 - val_accuracy: 0.3998\n",
      "Epoch 9/300\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 1.6359 - accuracy: 0.4017 - val_loss: 1.5692 - val_accuracy: 0.4175\n",
      "Epoch 10/300\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 1.6138 - accuracy: 0.4129 - val_loss: 1.5921 - val_accuracy: 0.4151\n",
      "Epoch 11/300\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 1.5763 - accuracy: 0.4192 - val_loss: 1.5734 - val_accuracy: 0.4319\n",
      "Epoch 12/300\n",
      "781/781 [==============================] - 43s 56ms/step - loss: 1.5616 - accuracy: 0.4366 - val_loss: 1.5206 - val_accuracy: 0.4215\n",
      "Epoch 13/300\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 1.5449 - accuracy: 0.4379 - val_loss: 1.5903 - val_accuracy: 0.4159\n",
      "Epoch 14/300\n",
      "781/781 [==============================] - 43s 56ms/step - loss: 1.5095 - accuracy: 0.4435 - val_loss: 1.4426 - val_accuracy: 0.4784\n",
      "Epoch 15/300\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 1.5030 - accuracy: 0.4453 - val_loss: 1.4233 - val_accuracy: 0.4888\n",
      "Epoch 16/300\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 1.4889 - accuracy: 0.4601 - val_loss: 1.4073 - val_accuracy: 0.4952\n",
      "Epoch 17/300\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 1.4659 - accuracy: 0.4657 - val_loss: 1.4297 - val_accuracy: 0.4816\n",
      "Epoch 18/300\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 1.4397 - accuracy: 0.4794 - val_loss: 1.4384 - val_accuracy: 0.4952\n",
      "Epoch 19/300\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 1.4357 - accuracy: 0.4760 - val_loss: 1.3979 - val_accuracy: 0.5048\n",
      "Epoch 20/300\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 1.4351 - accuracy: 0.4858 - val_loss: 1.3436 - val_accuracy: 0.4984\n",
      "Epoch 21/300\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 1.4059 - accuracy: 0.4891 - val_loss: 1.3667 - val_accuracy: 0.5224\n",
      "Epoch 22/300\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 1.3790 - accuracy: 0.4971 - val_loss: 1.2966 - val_accuracy: 0.5425\n",
      "Epoch 23/300\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 1.3713 - accuracy: 0.5125 - val_loss: 1.1848 - val_accuracy: 0.5577\n",
      "Epoch 24/300\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 1.3729 - accuracy: 0.5048 - val_loss: 1.3468 - val_accuracy: 0.5256\n",
      "Epoch 25/300\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 1.3515 - accuracy: 0.5064 - val_loss: 1.3253 - val_accuracy: 0.5441\n",
      "Epoch 26/300\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 1.3393 - accuracy: 0.5181 - val_loss: 1.3108 - val_accuracy: 0.5329\n",
      "Epoch 27/300\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 1.3266 - accuracy: 0.5176 - val_loss: 1.6732 - val_accuracy: 0.4768\n",
      "Epoch 28/300\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 1.2947 - accuracy: 0.5327 - val_loss: 1.1859 - val_accuracy: 0.5729\n",
      "Epoch 29/300\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 1.2991 - accuracy: 0.5309 - val_loss: 1.2919 - val_accuracy: 0.5457\n",
      "Epoch 30/300\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 1.2964 - accuracy: 0.5370 - val_loss: 1.1820 - val_accuracy: 0.5777\n",
      "Epoch 31/300\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 1.2861 - accuracy: 0.5413 - val_loss: 1.1760 - val_accuracy: 0.5729\n",
      "Epoch 32/300\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 1.2719 - accuracy: 0.5367 - val_loss: 1.2312 - val_accuracy: 0.5537\n",
      "Epoch 33/300\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 1.2628 - accuracy: 0.5461 - val_loss: 1.2261 - val_accuracy: 0.5657\n",
      "Epoch 34/300\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 1.2473 - accuracy: 0.5475 - val_loss: 1.1707 - val_accuracy: 0.5873\n",
      "Epoch 35/300\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 1.2621 - accuracy: 0.5461 - val_loss: 1.3340 - val_accuracy: 0.5353\n",
      "Epoch 36/300\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 1.2113 - accuracy: 0.5712 - val_loss: 1.1935 - val_accuracy: 0.5529\n",
      "Epoch 37/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.2239 - accuracy: 0.5549 - val_loss: 1.2532 - val_accuracy: 0.5809\n",
      "Epoch 38/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.2358 - accuracy: 0.5530 - val_loss: 1.2761 - val_accuracy: 0.5721\n",
      "Epoch 39/300\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 1.2062 - accuracy: 0.5725 - val_loss: 1.4571 - val_accuracy: 0.4960\n",
      "Epoch 40/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.2354 - accuracy: 0.5552 - val_loss: 1.0640 - val_accuracy: 0.6266\n",
      "Epoch 41/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.1989 - accuracy: 0.5703 - val_loss: 1.1194 - val_accuracy: 0.6090\n",
      "Epoch 42/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.1869 - accuracy: 0.5717 - val_loss: 1.1854 - val_accuracy: 0.5657\n",
      "Epoch 43/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.1758 - accuracy: 0.5755 - val_loss: 1.0936 - val_accuracy: 0.6042\n",
      "Epoch 44/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.1772 - accuracy: 0.5823 - val_loss: 1.3134 - val_accuracy: 0.5433\n",
      "Epoch 45/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.1786 - accuracy: 0.5781 - val_loss: 1.1374 - val_accuracy: 0.6050\n",
      "Epoch 46/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.1688 - accuracy: 0.5858 - val_loss: 1.0719 - val_accuracy: 0.6106\n",
      "Epoch 47/300\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 1.1710 - accuracy: 0.5775 - val_loss: 1.1137 - val_accuracy: 0.5809\n",
      "Epoch 48/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.1710 - accuracy: 0.5885 - val_loss: 1.0502 - val_accuracy: 0.6314\n",
      "Epoch 49/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.1642 - accuracy: 0.5861 - val_loss: 1.1252 - val_accuracy: 0.6018\n",
      "Epoch 50/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.1252 - accuracy: 0.6016 - val_loss: 1.1527 - val_accuracy: 0.6234\n",
      "Epoch 51/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.1256 - accuracy: 0.5986 - val_loss: 1.0687 - val_accuracy: 0.6226\n",
      "Epoch 52/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.1353 - accuracy: 0.5936 - val_loss: 1.0974 - val_accuracy: 0.6106\n",
      "Epoch 53/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.1507 - accuracy: 0.5853 - val_loss: 1.0386 - val_accuracy: 0.6266\n",
      "Epoch 54/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.1298 - accuracy: 0.6004 - val_loss: 1.0780 - val_accuracy: 0.6314\n",
      "Epoch 55/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.0994 - accuracy: 0.6085 - val_loss: 1.1993 - val_accuracy: 0.5970\n",
      "Epoch 56/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.1170 - accuracy: 0.6063 - val_loss: 1.0311 - val_accuracy: 0.6274\n",
      "Epoch 57/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.1079 - accuracy: 0.6079 - val_loss: 0.9964 - val_accuracy: 0.6466\n",
      "Epoch 58/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.1239 - accuracy: 0.5972 - val_loss: 1.0182 - val_accuracy: 0.6322\n",
      "Epoch 59/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.1045 - accuracy: 0.6015 - val_loss: 1.0318 - val_accuracy: 0.6178\n",
      "Epoch 60/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.1130 - accuracy: 0.6053 - val_loss: 1.0156 - val_accuracy: 0.6410\n",
      "Epoch 61/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0872 - accuracy: 0.6108 - val_loss: 1.0144 - val_accuracy: 0.6474\n",
      "Epoch 62/300\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 1.0853 - accuracy: 0.6180 - val_loss: 0.9569 - val_accuracy: 0.6723\n",
      "Epoch 63/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0694 - accuracy: 0.6180 - val_loss: 1.1051 - val_accuracy: 0.6122\n",
      "Epoch 64/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.1087 - accuracy: 0.6056 - val_loss: 0.9357 - val_accuracy: 0.6514\n",
      "Epoch 65/300\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 1.0829 - accuracy: 0.6173 - val_loss: 0.9728 - val_accuracy: 0.6603\n",
      "Epoch 66/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.1063 - accuracy: 0.6096 - val_loss: 0.9691 - val_accuracy: 0.6530\n",
      "Epoch 67/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0718 - accuracy: 0.6181 - val_loss: 0.9127 - val_accuracy: 0.6643\n",
      "Epoch 68/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0827 - accuracy: 0.6090 - val_loss: 1.0345 - val_accuracy: 0.6218\n",
      "Epoch 69/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0702 - accuracy: 0.6226 - val_loss: 1.0052 - val_accuracy: 0.6354\n",
      "Epoch 70/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0699 - accuracy: 0.6164 - val_loss: 0.9617 - val_accuracy: 0.6514\n",
      "Epoch 71/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0556 - accuracy: 0.6255 - val_loss: 1.1353 - val_accuracy: 0.6234\n",
      "Epoch 72/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0797 - accuracy: 0.6122 - val_loss: 0.9290 - val_accuracy: 0.6571\n",
      "Epoch 73/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.0626 - accuracy: 0.6231 - val_loss: 1.0596 - val_accuracy: 0.6418\n",
      "Epoch 74/300\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 1.0391 - accuracy: 0.6304 - val_loss: 0.9510 - val_accuracy: 0.6667\n",
      "Epoch 75/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0512 - accuracy: 0.6282 - val_loss: 0.9469 - val_accuracy: 0.6627\n",
      "Epoch 76/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.0387 - accuracy: 0.6296 - val_loss: 1.1118 - val_accuracy: 0.6266\n",
      "Epoch 77/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0566 - accuracy: 0.6226 - val_loss: 0.9157 - val_accuracy: 0.6859\n",
      "Epoch 78/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0454 - accuracy: 0.6293 - val_loss: 1.1335 - val_accuracy: 0.6410\n",
      "Epoch 79/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0431 - accuracy: 0.6308 - val_loss: 0.8829 - val_accuracy: 0.6755\n",
      "Epoch 80/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0195 - accuracy: 0.6380 - val_loss: 0.9600 - val_accuracy: 0.6779\n",
      "Epoch 81/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0512 - accuracy: 0.6231 - val_loss: 0.8709 - val_accuracy: 0.6811\n",
      "Epoch 82/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0363 - accuracy: 0.6328 - val_loss: 0.9307 - val_accuracy: 0.6835\n",
      "Epoch 83/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0351 - accuracy: 0.6288 - val_loss: 0.9397 - val_accuracy: 0.6747\n",
      "Epoch 84/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0229 - accuracy: 0.6367 - val_loss: 0.9695 - val_accuracy: 0.6546\n",
      "Epoch 85/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0282 - accuracy: 0.6357 - val_loss: 0.8930 - val_accuracy: 0.6779\n",
      "Epoch 86/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0040 - accuracy: 0.6431 - val_loss: 0.9701 - val_accuracy: 0.6579\n",
      "Epoch 87/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0215 - accuracy: 0.6396 - val_loss: 0.8640 - val_accuracy: 0.6843\n",
      "Epoch 88/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0060 - accuracy: 0.6394 - val_loss: 0.9681 - val_accuracy: 0.6699\n",
      "Epoch 89/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0343 - accuracy: 0.6372 - val_loss: 0.9459 - val_accuracy: 0.6546\n",
      "Epoch 90/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9910 - accuracy: 0.6442 - val_loss: 0.9328 - val_accuracy: 0.6859\n",
      "Epoch 91/300\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.0211 - accuracy: 0.6304 - val_loss: 0.9344 - val_accuracy: 0.6683\n",
      "Epoch 92/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9927 - accuracy: 0.6450 - val_loss: 0.9618 - val_accuracy: 0.6611\n",
      "Epoch 93/300\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.9828 - accuracy: 0.6480 - val_loss: 0.9190 - val_accuracy: 0.6915\n",
      "Epoch 94/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 1.0338 - accuracy: 0.6330 - val_loss: 0.9100 - val_accuracy: 0.6811\n",
      "Epoch 95/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0065 - accuracy: 0.6424 - val_loss: 0.8829 - val_accuracy: 0.6859\n",
      "Epoch 96/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0055 - accuracy: 0.6440 - val_loss: 0.8951 - val_accuracy: 0.6771\n",
      "Epoch 97/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0170 - accuracy: 0.6388 - val_loss: 0.8223 - val_accuracy: 0.7043\n",
      "Epoch 98/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 1.0115 - accuracy: 0.6463 - val_loss: 0.9433 - val_accuracy: 0.6667\n",
      "Epoch 99/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9990 - accuracy: 0.6437 - val_loss: 0.8486 - val_accuracy: 0.7003\n",
      "Epoch 100/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9921 - accuracy: 0.6474 - val_loss: 0.9042 - val_accuracy: 0.6851\n",
      "Epoch 101/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 1.0062 - accuracy: 0.6461 - val_loss: 0.9126 - val_accuracy: 0.6739\n",
      "Epoch 102/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9925 - accuracy: 0.6527 - val_loss: 0.8874 - val_accuracy: 0.6811\n",
      "Epoch 103/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9860 - accuracy: 0.6484 - val_loss: 0.8433 - val_accuracy: 0.7019\n",
      "Epoch 104/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9754 - accuracy: 0.6577 - val_loss: 0.8824 - val_accuracy: 0.6835\n",
      "Epoch 105/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9915 - accuracy: 0.6532 - val_loss: 0.9297 - val_accuracy: 0.6803\n",
      "Epoch 106/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9747 - accuracy: 0.6565 - val_loss: 0.8968 - val_accuracy: 0.6915\n",
      "Epoch 107/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9887 - accuracy: 0.6495 - val_loss: 0.9054 - val_accuracy: 0.6795\n",
      "Epoch 108/300\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.9906 - accuracy: 0.6479 - val_loss: 0.9326 - val_accuracy: 0.6891\n",
      "Epoch 109/300\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.9685 - accuracy: 0.6509 - val_loss: 0.8356 - val_accuracy: 0.7059\n",
      "Epoch 110/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9567 - accuracy: 0.6628 - val_loss: 0.8448 - val_accuracy: 0.6979\n",
      "Epoch 111/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9750 - accuracy: 0.6594 - val_loss: 0.9567 - val_accuracy: 0.6715\n",
      "Epoch 112/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9639 - accuracy: 0.6674 - val_loss: 0.8018 - val_accuracy: 0.7228\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9530 - accuracy: 0.6591 - val_loss: 0.7882 - val_accuracy: 0.7388\n",
      "Epoch 114/300\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.9626 - accuracy: 0.6520 - val_loss: 0.8717 - val_accuracy: 0.6931\n",
      "Epoch 115/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9471 - accuracy: 0.6615 - val_loss: 0.9380 - val_accuracy: 0.6811\n",
      "Epoch 116/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9548 - accuracy: 0.6613 - val_loss: 0.9773 - val_accuracy: 0.6691\n",
      "Epoch 117/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9670 - accuracy: 0.6557 - val_loss: 0.8727 - val_accuracy: 0.6899\n",
      "Epoch 118/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9479 - accuracy: 0.6633 - val_loss: 0.8680 - val_accuracy: 0.6819\n",
      "Epoch 119/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9509 - accuracy: 0.6687 - val_loss: 0.8748 - val_accuracy: 0.6867\n",
      "Epoch 120/300\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.9653 - accuracy: 0.6552 - val_loss: 0.8656 - val_accuracy: 0.7027\n",
      "Epoch 121/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9466 - accuracy: 0.6681 - val_loss: 0.8870 - val_accuracy: 0.6987\n",
      "Epoch 122/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9662 - accuracy: 0.6634 - val_loss: 0.8491 - val_accuracy: 0.6987\n",
      "Epoch 123/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9804 - accuracy: 0.6544 - val_loss: 0.9909 - val_accuracy: 0.6595\n",
      "Epoch 124/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9683 - accuracy: 0.6605 - val_loss: 0.7826 - val_accuracy: 0.7196\n",
      "Epoch 125/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9378 - accuracy: 0.6753 - val_loss: 0.8195 - val_accuracy: 0.7043\n",
      "Epoch 126/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9461 - accuracy: 0.6644 - val_loss: 0.8464 - val_accuracy: 0.6971\n",
      "Epoch 127/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9560 - accuracy: 0.6633 - val_loss: 0.9045 - val_accuracy: 0.6835\n",
      "Epoch 128/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9318 - accuracy: 0.6676 - val_loss: 0.8378 - val_accuracy: 0.7019\n",
      "Epoch 129/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9032 - accuracy: 0.6813 - val_loss: 0.9070 - val_accuracy: 0.6843\n",
      "Epoch 130/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9332 - accuracy: 0.6703 - val_loss: 0.8635 - val_accuracy: 0.7011\n",
      "Epoch 131/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9466 - accuracy: 0.6633 - val_loss: 0.8653 - val_accuracy: 0.6907\n",
      "Epoch 132/300\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.9478 - accuracy: 0.6684 - val_loss: 0.8655 - val_accuracy: 0.7059\n",
      "Epoch 133/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9227 - accuracy: 0.6770 - val_loss: 0.8792 - val_accuracy: 0.6899\n",
      "Epoch 134/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9473 - accuracy: 0.6698 - val_loss: 0.8058 - val_accuracy: 0.7204\n",
      "Epoch 135/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9275 - accuracy: 0.6690 - val_loss: 0.8881 - val_accuracy: 0.6947\n",
      "Epoch 136/300\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.9300 - accuracy: 0.6684 - val_loss: 0.8595 - val_accuracy: 0.6955\n",
      "Epoch 137/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9147 - accuracy: 0.6785 - val_loss: 0.7925 - val_accuracy: 0.7099\n",
      "Epoch 138/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9137 - accuracy: 0.6804 - val_loss: 0.9568 - val_accuracy: 0.6659\n",
      "Epoch 139/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9278 - accuracy: 0.6653 - val_loss: 0.8273 - val_accuracy: 0.7139\n",
      "Epoch 140/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9502 - accuracy: 0.6697 - val_loss: 0.8502 - val_accuracy: 0.6835\n",
      "Epoch 141/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9265 - accuracy: 0.6737 - val_loss: 0.8480 - val_accuracy: 0.7035\n",
      "Epoch 142/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9307 - accuracy: 0.6745 - val_loss: 0.8790 - val_accuracy: 0.7075\n",
      "Epoch 143/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9389 - accuracy: 0.6748 - val_loss: 0.8394 - val_accuracy: 0.7163\n",
      "Epoch 144/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9156 - accuracy: 0.6817 - val_loss: 0.8308 - val_accuracy: 0.7268\n",
      "Epoch 145/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9297 - accuracy: 0.6775 - val_loss: 0.7907 - val_accuracy: 0.7332\n",
      "Epoch 146/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9184 - accuracy: 0.6708 - val_loss: 0.8471 - val_accuracy: 0.7163\n",
      "Epoch 147/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9432 - accuracy: 0.6778 - val_loss: 0.8436 - val_accuracy: 0.7059\n",
      "Epoch 148/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9201 - accuracy: 0.6770 - val_loss: 0.7723 - val_accuracy: 0.7236\n",
      "Epoch 149/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9242 - accuracy: 0.6767 - val_loss: 0.8032 - val_accuracy: 0.7204\n",
      "Epoch 150/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9233 - accuracy: 0.6746 - val_loss: 0.8892 - val_accuracy: 0.6915\n",
      "Epoch 151/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9307 - accuracy: 0.6741 - val_loss: 0.8204 - val_accuracy: 0.7099\n",
      "Epoch 152/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9131 - accuracy: 0.6799 - val_loss: 0.8461 - val_accuracy: 0.6979\n",
      "Epoch 153/300\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.9033 - accuracy: 0.6853 - val_loss: 0.8521 - val_accuracy: 0.7091\n",
      "Epoch 154/300\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.9189 - accuracy: 0.6818 - val_loss: 0.8215 - val_accuracy: 0.7196\n",
      "Epoch 155/300\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.8931 - accuracy: 0.6874 - val_loss: 0.8424 - val_accuracy: 0.7139\n",
      "Epoch 156/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8990 - accuracy: 0.6863 - val_loss: 0.8511 - val_accuracy: 0.6987\n",
      "Epoch 157/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9042 - accuracy: 0.6893 - val_loss: 0.8409 - val_accuracy: 0.7011\n",
      "Epoch 158/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9098 - accuracy: 0.6844 - val_loss: 0.7638 - val_accuracy: 0.7348\n",
      "Epoch 159/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9025 - accuracy: 0.6893 - val_loss: 0.8168 - val_accuracy: 0.7244\n",
      "Epoch 160/300\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.9001 - accuracy: 0.6804 - val_loss: 0.8519 - val_accuracy: 0.6899\n",
      "Epoch 161/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8767 - accuracy: 0.6953 - val_loss: 0.7729 - val_accuracy: 0.7324\n",
      "Epoch 162/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8936 - accuracy: 0.6868 - val_loss: 0.8174 - val_accuracy: 0.7075\n",
      "Epoch 163/300\n",
      "781/781 [==============================] - 36s 46ms/step - loss: 0.9230 - accuracy: 0.6719 - val_loss: 0.8229 - val_accuracy: 0.7099\n",
      "Epoch 164/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8823 - accuracy: 0.6909 - val_loss: 0.8411 - val_accuracy: 0.7123\n",
      "Epoch 165/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9087 - accuracy: 0.6853 - val_loss: 0.7914 - val_accuracy: 0.7155\n",
      "Epoch 166/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9147 - accuracy: 0.6791 - val_loss: 0.8159 - val_accuracy: 0.7204\n",
      "Epoch 167/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9106 - accuracy: 0.6817 - val_loss: 0.8898 - val_accuracy: 0.6819\n",
      "Epoch 168/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9170 - accuracy: 0.6769 - val_loss: 0.8351 - val_accuracy: 0.7059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9190 - accuracy: 0.6762 - val_loss: 0.7652 - val_accuracy: 0.7348\n",
      "Epoch 170/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9047 - accuracy: 0.6821 - val_loss: 0.8218 - val_accuracy: 0.7220\n",
      "Epoch 171/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9011 - accuracy: 0.6823 - val_loss: 0.8375 - val_accuracy: 0.7123\n",
      "Epoch 172/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.9073 - accuracy: 0.6807 - val_loss: 0.8194 - val_accuracy: 0.7171\n",
      "Epoch 173/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8884 - accuracy: 0.6911 - val_loss: 0.8394 - val_accuracy: 0.7075\n",
      "Epoch 174/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8932 - accuracy: 0.6882 - val_loss: 0.8590 - val_accuracy: 0.7059\n",
      "Epoch 175/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8963 - accuracy: 0.6855 - val_loss: 0.8166 - val_accuracy: 0.7236\n",
      "Epoch 176/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8802 - accuracy: 0.6921 - val_loss: 0.8788 - val_accuracy: 0.6947\n",
      "Epoch 177/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8825 - accuracy: 0.6916 - val_loss: 0.8380 - val_accuracy: 0.7019\n",
      "Epoch 178/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9045 - accuracy: 0.6893 - val_loss: 0.7543 - val_accuracy: 0.7332\n",
      "Epoch 179/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8980 - accuracy: 0.6852 - val_loss: 0.8733 - val_accuracy: 0.7043\n",
      "Epoch 180/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8765 - accuracy: 0.6927 - val_loss: 0.8469 - val_accuracy: 0.7011\n",
      "Epoch 181/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8708 - accuracy: 0.6978 - val_loss: 0.7530 - val_accuracy: 0.7356\n",
      "Epoch 182/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8896 - accuracy: 0.6879 - val_loss: 0.7680 - val_accuracy: 0.7236\n",
      "Epoch 183/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8778 - accuracy: 0.6890 - val_loss: 0.9005 - val_accuracy: 0.6963\n",
      "Epoch 184/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8969 - accuracy: 0.6844 - val_loss: 0.8226 - val_accuracy: 0.7131\n",
      "Epoch 185/300\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.8684 - accuracy: 0.6986 - val_loss: 0.8910 - val_accuracy: 0.6867\n",
      "Epoch 186/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8888 - accuracy: 0.6887 - val_loss: 0.8653 - val_accuracy: 0.7091\n",
      "Epoch 187/300\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.8544 - accuracy: 0.7044 - val_loss: 0.7865 - val_accuracy: 0.7139\n",
      "Epoch 188/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8662 - accuracy: 0.6957 - val_loss: 0.7459 - val_accuracy: 0.7332\n",
      "Epoch 189/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.9050 - accuracy: 0.6865 - val_loss: 0.7220 - val_accuracy: 0.7444\n",
      "Epoch 190/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8855 - accuracy: 0.6921 - val_loss: 0.8236 - val_accuracy: 0.7171\n",
      "Epoch 191/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8886 - accuracy: 0.6956 - val_loss: 0.7931 - val_accuracy: 0.7196\n",
      "Epoch 192/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8803 - accuracy: 0.6941 - val_loss: 0.7652 - val_accuracy: 0.7324\n",
      "Epoch 193/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8877 - accuracy: 0.6837 - val_loss: 0.7577 - val_accuracy: 0.7428\n",
      "Epoch 194/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8744 - accuracy: 0.6906 - val_loss: 0.7391 - val_accuracy: 0.7412\n",
      "Epoch 195/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.9147 - accuracy: 0.6780 - val_loss: 0.7344 - val_accuracy: 0.7572\n",
      "Epoch 196/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8748 - accuracy: 0.6885 - val_loss: 0.8393 - val_accuracy: 0.7067\n",
      "Epoch 197/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8681 - accuracy: 0.6933 - val_loss: 0.7646 - val_accuracy: 0.7428\n",
      "Epoch 198/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8755 - accuracy: 0.6997 - val_loss: 0.7869 - val_accuracy: 0.7420\n",
      "Epoch 199/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8707 - accuracy: 0.6909 - val_loss: 0.8055 - val_accuracy: 0.7019\n",
      "Epoch 200/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8728 - accuracy: 0.6900 - val_loss: 0.7602 - val_accuracy: 0.7292\n",
      "Epoch 201/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8571 - accuracy: 0.6973 - val_loss: 0.7058 - val_accuracy: 0.7604\n",
      "Epoch 202/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8696 - accuracy: 0.6957 - val_loss: 0.7614 - val_accuracy: 0.7244\n",
      "Epoch 203/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8654 - accuracy: 0.6962 - val_loss: 0.7395 - val_accuracy: 0.7372\n",
      "Epoch 204/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8568 - accuracy: 0.6935 - val_loss: 0.7671 - val_accuracy: 0.7308\n",
      "Epoch 205/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8739 - accuracy: 0.6951 - val_loss: 0.8373 - val_accuracy: 0.7051\n",
      "Epoch 206/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8884 - accuracy: 0.6964 - val_loss: 0.7701 - val_accuracy: 0.7188\n",
      "Epoch 207/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8593 - accuracy: 0.6993 - val_loss: 0.8042 - val_accuracy: 0.7324\n",
      "Epoch 208/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8540 - accuracy: 0.6989 - val_loss: 0.8336 - val_accuracy: 0.7003\n",
      "Epoch 209/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8729 - accuracy: 0.6903 - val_loss: 0.8840 - val_accuracy: 0.7155\n",
      "Epoch 210/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8441 - accuracy: 0.7042 - val_loss: 0.7155 - val_accuracy: 0.7556\n",
      "Epoch 211/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8703 - accuracy: 0.6906 - val_loss: 0.8416 - val_accuracy: 0.7059\n",
      "Epoch 212/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8589 - accuracy: 0.7036 - val_loss: 0.7711 - val_accuracy: 0.7276\n",
      "Epoch 213/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8438 - accuracy: 0.7071 - val_loss: 0.7640 - val_accuracy: 0.7292\n",
      "Epoch 214/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8791 - accuracy: 0.6929 - val_loss: 0.7951 - val_accuracy: 0.7284\n",
      "Epoch 215/300\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.8719 - accuracy: 0.6938 - val_loss: 0.7420 - val_accuracy: 0.7332\n",
      "Epoch 216/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8834 - accuracy: 0.6898 - val_loss: 0.8049 - val_accuracy: 0.7155\n",
      "Epoch 217/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8381 - accuracy: 0.7097 - val_loss: 0.7654 - val_accuracy: 0.7444\n",
      "Epoch 218/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8736 - accuracy: 0.6895 - val_loss: 0.7183 - val_accuracy: 0.7380\n",
      "Epoch 219/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8526 - accuracy: 0.7050 - val_loss: 0.7668 - val_accuracy: 0.7452\n",
      "Epoch 220/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8447 - accuracy: 0.7041 - val_loss: 0.6968 - val_accuracy: 0.7548\n",
      "Epoch 221/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8415 - accuracy: 0.7057 - val_loss: 0.7680 - val_accuracy: 0.7171\n",
      "Epoch 222/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8410 - accuracy: 0.7057 - val_loss: 0.7441 - val_accuracy: 0.7380\n",
      "Epoch 223/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8547 - accuracy: 0.6970 - val_loss: 0.7924 - val_accuracy: 0.7179\n",
      "Epoch 224/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8702 - accuracy: 0.6949 - val_loss: 0.7032 - val_accuracy: 0.7564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8490 - accuracy: 0.6932 - val_loss: 0.8119 - val_accuracy: 0.7252\n",
      "Epoch 226/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8644 - accuracy: 0.6970 - val_loss: 0.7336 - val_accuracy: 0.7444\n",
      "Epoch 227/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8648 - accuracy: 0.6997 - val_loss: 0.7411 - val_accuracy: 0.7364\n",
      "Epoch 228/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8475 - accuracy: 0.7017 - val_loss: 0.7566 - val_accuracy: 0.7332\n",
      "Epoch 229/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8433 - accuracy: 0.7049 - val_loss: 0.7410 - val_accuracy: 0.7420\n",
      "Epoch 230/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8278 - accuracy: 0.7141 - val_loss: 0.7500 - val_accuracy: 0.7388\n",
      "Epoch 231/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8483 - accuracy: 0.7071 - val_loss: 0.7273 - val_accuracy: 0.7628\n",
      "Epoch 232/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8360 - accuracy: 0.7033 - val_loss: 0.7746 - val_accuracy: 0.7300\n",
      "Epoch 233/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8674 - accuracy: 0.6887 - val_loss: 0.8213 - val_accuracy: 0.7107\n",
      "Epoch 234/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8245 - accuracy: 0.7151 - val_loss: 0.6627 - val_accuracy: 0.7596\n",
      "Epoch 235/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8443 - accuracy: 0.7018 - val_loss: 0.6836 - val_accuracy: 0.7684\n",
      "Epoch 236/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8210 - accuracy: 0.7156 - val_loss: 0.7853 - val_accuracy: 0.7324\n",
      "Epoch 237/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8384 - accuracy: 0.7074 - val_loss: 0.7671 - val_accuracy: 0.7372\n",
      "Epoch 238/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8514 - accuracy: 0.7060 - val_loss: 0.7767 - val_accuracy: 0.7188\n",
      "Epoch 239/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8247 - accuracy: 0.7074 - val_loss: 0.7343 - val_accuracy: 0.7404\n",
      "Epoch 240/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8346 - accuracy: 0.7057 - val_loss: 0.7051 - val_accuracy: 0.7380\n",
      "Epoch 241/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8483 - accuracy: 0.7031 - val_loss: 0.7049 - val_accuracy: 0.7532\n",
      "Epoch 242/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8444 - accuracy: 0.7108 - val_loss: 0.8105 - val_accuracy: 0.7276\n",
      "Epoch 243/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8388 - accuracy: 0.7055 - val_loss: 0.7255 - val_accuracy: 0.7524\n",
      "Epoch 244/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8343 - accuracy: 0.7002 - val_loss: 0.7387 - val_accuracy: 0.7268\n",
      "Epoch 245/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8378 - accuracy: 0.7058 - val_loss: 0.8787 - val_accuracy: 0.7091\n",
      "Epoch 246/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8340 - accuracy: 0.7130 - val_loss: 0.7607 - val_accuracy: 0.7388\n",
      "Epoch 247/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8356 - accuracy: 0.7034 - val_loss: 0.7042 - val_accuracy: 0.7660\n",
      "Epoch 248/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8217 - accuracy: 0.7101 - val_loss: 0.7430 - val_accuracy: 0.7380\n",
      "Epoch 249/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8320 - accuracy: 0.7079 - val_loss: 0.7425 - val_accuracy: 0.7396\n",
      "Epoch 250/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8494 - accuracy: 0.6951 - val_loss: 0.7785 - val_accuracy: 0.7340\n",
      "Epoch 251/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8387 - accuracy: 0.7058 - val_loss: 0.6942 - val_accuracy: 0.7508\n",
      "Epoch 252/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8258 - accuracy: 0.7132 - val_loss: 0.6756 - val_accuracy: 0.7756\n",
      "Epoch 253/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8361 - accuracy: 0.7058 - val_loss: 0.7467 - val_accuracy: 0.7492\n",
      "Epoch 254/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8288 - accuracy: 0.7111 - val_loss: 0.8284 - val_accuracy: 0.7340\n",
      "Epoch 255/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8237 - accuracy: 0.7081 - val_loss: 0.7383 - val_accuracy: 0.7524\n",
      "Epoch 256/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8369 - accuracy: 0.7031 - val_loss: 0.7244 - val_accuracy: 0.7492\n",
      "Epoch 257/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8033 - accuracy: 0.7196 - val_loss: 0.7752 - val_accuracy: 0.7252\n",
      "Epoch 258/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8114 - accuracy: 0.7153 - val_loss: 0.6925 - val_accuracy: 0.7540\n",
      "Epoch 259/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8214 - accuracy: 0.7081 - val_loss: 0.7268 - val_accuracy: 0.7468\n",
      "Epoch 260/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.7993 - accuracy: 0.7156 - val_loss: 0.7642 - val_accuracy: 0.7292\n",
      "Epoch 261/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8204 - accuracy: 0.7111 - val_loss: 0.8166 - val_accuracy: 0.7075\n",
      "Epoch 262/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8434 - accuracy: 0.7058 - val_loss: 0.7275 - val_accuracy: 0.7484\n",
      "Epoch 263/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8242 - accuracy: 0.7081 - val_loss: 0.6840 - val_accuracy: 0.7580\n",
      "Epoch 264/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8099 - accuracy: 0.7214 - val_loss: 0.7168 - val_accuracy: 0.7604\n",
      "Epoch 265/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8309 - accuracy: 0.7137 - val_loss: 0.7395 - val_accuracy: 0.7348\n",
      "Epoch 266/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8422 - accuracy: 0.7073 - val_loss: 0.7119 - val_accuracy: 0.7572\n",
      "Epoch 267/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8400 - accuracy: 0.7017 - val_loss: 0.7278 - val_accuracy: 0.7604\n",
      "Epoch 268/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8355 - accuracy: 0.7071 - val_loss: 0.7115 - val_accuracy: 0.7500\n",
      "Epoch 269/300\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.8480 - accuracy: 0.7052 - val_loss: 0.7349 - val_accuracy: 0.7484\n",
      "Epoch 270/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8286 - accuracy: 0.7090 - val_loss: 0.7396 - val_accuracy: 0.7292\n",
      "Epoch 271/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8351 - accuracy: 0.7050 - val_loss: 0.7209 - val_accuracy: 0.7420\n",
      "Epoch 272/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8235 - accuracy: 0.7089 - val_loss: 0.7073 - val_accuracy: 0.7588\n",
      "Epoch 273/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8145 - accuracy: 0.7135 - val_loss: 0.6771 - val_accuracy: 0.7812\n",
      "Epoch 274/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8307 - accuracy: 0.7097 - val_loss: 0.7190 - val_accuracy: 0.7484\n",
      "Epoch 275/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8213 - accuracy: 0.7135 - val_loss: 0.8552 - val_accuracy: 0.7188\n",
      "Epoch 276/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8298 - accuracy: 0.7101 - val_loss: 0.8182 - val_accuracy: 0.7292\n",
      "Epoch 277/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8113 - accuracy: 0.7202 - val_loss: 0.7254 - val_accuracy: 0.7508\n",
      "Epoch 278/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8196 - accuracy: 0.7125 - val_loss: 0.7325 - val_accuracy: 0.7452\n",
      "Epoch 279/300\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.8075 - accuracy: 0.7122 - val_loss: 0.7772 - val_accuracy: 0.7372\n",
      "Epoch 280/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8358 - accuracy: 0.7129 - val_loss: 0.7035 - val_accuracy: 0.7420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/300\n",
      "781/781 [==============================] - 36s 47ms/step - loss: 0.8246 - accuracy: 0.7149 - val_loss: 0.7405 - val_accuracy: 0.7460\n",
      "Epoch 282/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8065 - accuracy: 0.7119 - val_loss: 0.7548 - val_accuracy: 0.7420\n",
      "Epoch 283/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8056 - accuracy: 0.7209 - val_loss: 0.7068 - val_accuracy: 0.7492\n",
      "Epoch 284/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8286 - accuracy: 0.7090 - val_loss: 0.7072 - val_accuracy: 0.7612\n",
      "Epoch 285/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8170 - accuracy: 0.7156 - val_loss: 0.6463 - val_accuracy: 0.7804\n",
      "Epoch 286/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8309 - accuracy: 0.7153 - val_loss: 0.6934 - val_accuracy: 0.7540\n",
      "Epoch 287/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8092 - accuracy: 0.7210 - val_loss: 0.7491 - val_accuracy: 0.7468\n",
      "Epoch 288/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8175 - accuracy: 0.7143 - val_loss: 0.7924 - val_accuracy: 0.7300\n",
      "Epoch 289/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8449 - accuracy: 0.6991 - val_loss: 0.7693 - val_accuracy: 0.7532\n",
      "Epoch 290/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8296 - accuracy: 0.7058 - val_loss: 0.6903 - val_accuracy: 0.7596\n",
      "Epoch 291/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8174 - accuracy: 0.7175 - val_loss: 0.6743 - val_accuracy: 0.7764\n",
      "Epoch 292/300\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.8238 - accuracy: 0.7085 - val_loss: 0.7189 - val_accuracy: 0.7428\n",
      "Epoch 293/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8233 - accuracy: 0.7101 - val_loss: 0.7238 - val_accuracy: 0.7572\n",
      "Epoch 294/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8210 - accuracy: 0.7117 - val_loss: 0.7369 - val_accuracy: 0.7460\n",
      "Epoch 295/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8045 - accuracy: 0.7188 - val_loss: 0.7323 - val_accuracy: 0.7468\n",
      "Epoch 296/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8263 - accuracy: 0.7055 - val_loss: 0.7037 - val_accuracy: 0.7564\n",
      "Epoch 297/300\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.8117 - accuracy: 0.7199 - val_loss: 0.6653 - val_accuracy: 0.7660\n",
      "Epoch 298/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.7986 - accuracy: 0.7223 - val_loss: 0.7596 - val_accuracy: 0.7612\n",
      "Epoch 299/300\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.8126 - accuracy: 0.7130 - val_loss: 0.7219 - val_accuracy: 0.7476\n",
      "Epoch 300/300\n",
      "781/781 [==============================] - 38s 48ms/step - loss: 0.8161 - accuracy: 0.7127 - val_loss: 0.7188 - val_accuracy: 0.7572\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.7809 - accuracy: 0.7442\n",
      "Test loss: 0.7808642387390137\n",
      "Test accuracy: 0.7441999912261963\n",
      "Saved model to disk\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "dense_model_2(X_train, y_train, X_test, y_test, batch_size, step_size, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLb8tJaV54RY"
   },
   "source": [
    "## DENSENET MODEL AS IN RESEARCH PAPER(Bottleneck + No augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 4\n",
    "num_classes = 10\n",
    "epochs =20\n",
    "l = 12\n",
    "num_filter = 32\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter = 12, dropout_rate = 0.2, l=12):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_5_5 = layers.Conv2D(int(num_filter*4), (1,1), use_bias=False ,padding='same')(relu)\n",
    "        Conv2D_5_5 = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(Conv2D_5_5)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_5_5 = layers.Dropout(dropout_rate)(Conv2D_5_5)\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_5_5])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Blosck\n",
    "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(num_filter, (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_model(input_shape = (32,32,3), n_classes = 10):\n",
    "    X_input = Input(shape=(img_height, img_width, channel))\n",
    "    First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(X_input)\n",
    "    \n",
    "    First_Block = denseblock(First_Conv2D, num_filter, dropout_rate,l=6)\n",
    "    First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "    Second_Block = denseblock(First_Transition, num_filter, dropout_rate,l=12)\n",
    "    Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "    Third_Block = denseblock(Second_Transition, num_filter, dropout_rate,l=24)\n",
    "    Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "    Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate,l=16)\n",
    "    output = output_layer(Last_Block)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 32, 32, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 32, 32)   128         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 32, 32, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 32, 32, 128)  4096        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 32, 32, 32)   36864       conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 32, 32, 32)   0           conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 32, 32, 64)   0           conv2d_120[0][0]                 \n",
      "                                                                 dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 32, 64)   256         concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 32, 32, 64)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 32, 32, 128)  8192        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 32, 32, 32)   36864       conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 32, 32, 32)   0           conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 32, 32, 96)   0           concatenate_58[0][0]             \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 32, 32, 96)   384         concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 32, 32, 96)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 32, 32, 128)  12288       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 32, 32, 32)   36864       conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 32, 32, 32)   0           conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 32, 32, 128)  0           concatenate_59[0][0]             \n",
      "                                                                 dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 32, 32, 128)  512         concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 32, 32, 128)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 32, 32, 128)  16384       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 32, 32, 32)   36864       conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 32, 32, 32)   0           conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 32, 32, 160)  0           concatenate_60[0][0]             \n",
      "                                                                 dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 32, 32, 160)  640         concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 32, 32, 160)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 32, 32, 128)  20480       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 32, 32, 32)   36864       conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 32, 32, 32)   0           conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 32, 32, 192)  0           concatenate_61[0][0]             \n",
      "                                                                 dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 32, 32, 192)  768         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 32, 32, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 32, 32, 128)  24576       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 32, 32, 32)   36864       conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 32, 32, 32)   0           conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 32, 32, 224)  0           concatenate_62[0][0]             \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 32, 32, 224)  896         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 32, 32, 224)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 32, 32, 32)   7168        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 32, 32, 32)   0           conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 16, 16, 32)   0           dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 16, 16, 32)   128         average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 16, 16, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 16, 16, 128)  4096        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 16, 16, 32)   36864       conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 16, 16, 32)   0           conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 16, 16, 64)   0           average_pooling2d_4[0][0]        \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 16, 16, 64)   256         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 16, 16, 64)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 16, 16, 128)  8192        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 16, 16, 32)   36864       conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 16, 16, 32)   0           conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 16, 16, 96)   0           concatenate_64[0][0]             \n",
      "                                                                 dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 16, 16, 96)   384         concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 16, 16, 96)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 16, 16, 128)  12288       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 16, 16, 32)   36864       conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 16, 16, 32)   0           conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 16, 16, 128)  0           concatenate_65[0][0]             \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 16, 16, 128)  512         concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 16, 16, 128)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 16, 16, 128)  16384       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 16, 16, 32)   36864       conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 16, 16, 32)   0           conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 16, 16, 160)  0           concatenate_66[0][0]             \n",
      "                                                                 dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 16, 16, 160)  640         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 16, 16, 160)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 16, 16, 128)  20480       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 16, 16, 32)   36864       conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 16, 16, 32)   0           conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 16, 16, 192)  0           concatenate_67[0][0]             \n",
      "                                                                 dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 16, 16, 192)  768         concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 16, 16, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 16, 16, 128)  24576       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 16, 16, 32)   36864       conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 16, 16, 32)   0           conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 16, 16, 224)  0           concatenate_68[0][0]             \n",
      "                                                                 dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 16, 16, 224)  896         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 16, 16, 224)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 16, 16, 128)  28672       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 16, 16, 32)   36864       conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 16, 16, 32)   0           conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 16, 16, 256)  0           concatenate_69[0][0]             \n",
      "                                                                 dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 16, 16, 256)  1024        concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 16, 16, 256)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 16, 16, 128)  32768       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 16, 16, 32)   36864       conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 16, 16, 32)   0           conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 16, 16, 288)  0           concatenate_70[0][0]             \n",
      "                                                                 dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 16, 16, 288)  1152        concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 16, 16, 288)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 16, 16, 128)  36864       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 16, 16, 32)   36864       conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 16, 16, 32)   0           conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 16, 16, 320)  0           concatenate_71[0][0]             \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 16, 16, 320)  1280        concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 16, 16, 320)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 16, 16, 128)  40960       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 16, 16, 32)   36864       conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 16, 16, 32)   0           conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 16, 16, 352)  0           concatenate_72[0][0]             \n",
      "                                                                 dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 16, 16, 352)  1408        concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 16, 16, 352)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 16, 16, 128)  45056       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 16, 16, 32)   36864       conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 16, 16, 32)   0           conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 16, 16, 384)  0           concatenate_73[0][0]             \n",
      "                                                                 dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 16, 16, 384)  1536        concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 16, 16, 384)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 16, 16, 128)  49152       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 16, 16, 32)   36864       conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 16, 16, 32)   0           conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 16, 16, 416)  0           concatenate_74[0][0]             \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 16, 16, 416)  1664        concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 16, 16, 416)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 16, 16, 32)   13312       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 16, 16, 32)   0           conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 8, 8, 32)     0           dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 32)     128         average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 32)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 8, 8, 128)    4096        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 8, 8, 32)     0           conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 8, 8, 64)     0           average_pooling2d_5[0][0]        \n",
      "                                                                 dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 64)     256         concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 64)     0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 8, 8, 128)    8192        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 8, 8, 32)     0           conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 8, 8, 96)     0           concatenate_76[0][0]             \n",
      "                                                                 dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 96)     384         concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 96)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 8, 8, 128)    12288       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 8, 8, 32)     0           conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 8, 8, 128)    0           concatenate_77[0][0]             \n",
      "                                                                 dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 128)    512         concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 128)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 8, 8, 128)    16384       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 8, 8, 32)     0           conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 8, 8, 160)    0           concatenate_78[0][0]             \n",
      "                                                                 dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 160)    640         concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 160)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 8, 8, 128)    20480       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 8, 8, 32)     0           conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 8, 8, 192)    0           concatenate_79[0][0]             \n",
      "                                                                 dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 192)    768         concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 192)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 128)    24576       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 8, 8, 32)     0           conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 8, 8, 224)    0           concatenate_80[0][0]             \n",
      "                                                                 dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 224)    896         concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 224)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 128)    28672       activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 8, 8, 32)     0           conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 8, 8, 256)    0           concatenate_81[0][0]             \n",
      "                                                                 dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 256)    1024        concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 256)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 128)    32768       activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 8, 8, 32)     0           conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 8, 8, 288)    0           concatenate_82[0][0]             \n",
      "                                                                 dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 288)    1152        concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 288)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 8, 8, 128)    36864       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 8, 8, 32)     0           conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 8, 8, 320)    0           concatenate_83[0][0]             \n",
      "                                                                 dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 320)    1280        concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 320)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 8, 8, 128)    40960       activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 8, 8, 32)     0           conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 8, 8, 352)    0           concatenate_84[0][0]             \n",
      "                                                                 dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 352)    1408        concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 352)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 8, 8, 128)    45056       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 8, 8, 32)     0           conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 8, 8, 384)    0           concatenate_85[0][0]             \n",
      "                                                                 dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1536        concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 8, 8, 128)    49152       activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 8, 8, 32)     0           conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 8, 8, 416)    0           concatenate_86[0][0]             \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 416)    1664        concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 416)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 8, 8, 128)    53248       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 8, 8, 32)     0           conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 8, 8, 448)    0           concatenate_87[0][0]             \n",
      "                                                                 dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 448)    1792        concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 8, 8, 448)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 8, 8, 128)    57344       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 8, 8, 32)     0           conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 8, 8, 480)    0           concatenate_88[0][0]             \n",
      "                                                                 dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 480)    1920        concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 480)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 8, 8, 128)    61440       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 8, 8, 32)     0           conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 8, 8, 512)    0           concatenate_89[0][0]             \n",
      "                                                                 dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8, 8, 512)    2048        concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, 8, 512)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 8, 8, 128)    65536       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 8, 8, 32)     0           conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 8, 8, 544)    0           concatenate_90[0][0]             \n",
      "                                                                 dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 544)    2176        concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 544)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 8, 8, 128)    69632       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 8, 8, 32)     0           conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 8, 8, 576)    0           concatenate_91[0][0]             \n",
      "                                                                 dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 8, 8, 576)    2304        concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 8, 8, 576)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 8, 8, 128)    73728       activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 8, 8, 32)     0           conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 8, 8, 608)    0           concatenate_92[0][0]             \n",
      "                                                                 dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 8, 8, 608)    2432        concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 8, 8, 608)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 8, 8, 128)    77824       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 8, 8, 32)     0           conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 8, 8, 640)    0           concatenate_93[0][0]             \n",
      "                                                                 dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 8, 8, 640)    2560        concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 8, 8, 640)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 8, 8, 128)    81920       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 8, 8, 32)     0           conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 8, 8, 672)    0           concatenate_94[0][0]             \n",
      "                                                                 dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 8, 8, 672)    2688        concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 8, 8, 672)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 8, 8, 128)    86016       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 8, 8, 32)     0           conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 8, 8, 704)    0           concatenate_95[0][0]             \n",
      "                                                                 dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 8, 8, 704)    2816        concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 8, 8, 704)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 8, 8, 128)    90112       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 8, 8, 32)     0           conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 8, 8, 736)    0           concatenate_96[0][0]             \n",
      "                                                                 dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 8, 8, 736)    2944        concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 8, 8, 736)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 8, 8, 128)    94208       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 8, 8, 32)     0           conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 8, 8, 768)    0           concatenate_97[0][0]             \n",
      "                                                                 dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 8, 8, 768)    3072        concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 8, 8, 768)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 8, 8, 128)    98304       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 8, 8, 32)     36864       conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 8, 8, 32)     0           conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 8, 8, 800)    0           concatenate_98[0][0]             \n",
      "                                                                 dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 8, 8, 800)    3200        concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 8, 8, 800)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 8, 8, 32)     25600       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 8, 8, 32)     0           conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 4, 4, 32)     0           dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 4, 4, 32)     128         average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 4, 4, 32)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 4, 4, 128)    4096        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 4, 4, 32)     0           conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 4, 4, 64)     0           average_pooling2d_6[0][0]        \n",
      "                                                                 dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 4, 4, 64)     256         concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 4, 4, 64)     0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 4, 4, 128)    8192        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 4, 4, 32)     0           conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 4, 4, 96)     0           concatenate_100[0][0]            \n",
      "                                                                 dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 4, 4, 96)     384         concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 4, 4, 96)     0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 4, 4, 128)    12288       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 4, 4, 32)     0           conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 4, 4, 128)    0           concatenate_101[0][0]            \n",
      "                                                                 dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 4, 4, 128)    512         concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 4, 4, 128)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 4, 4, 128)    16384       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 4, 4, 32)     0           conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 4, 4, 160)    0           concatenate_102[0][0]            \n",
      "                                                                 dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 4, 4, 160)    640         concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 4, 4, 160)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 4, 4, 128)    20480       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 4, 4, 32)     0           conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 4, 4, 192)    0           concatenate_103[0][0]            \n",
      "                                                                 dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 4, 4, 192)    768         concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 4, 4, 192)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 4, 4, 128)    24576       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 4, 4, 32)     0           conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 4, 4, 224)    0           concatenate_104[0][0]            \n",
      "                                                                 dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 4, 4, 224)    896         concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 4, 4, 224)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 4, 4, 128)    28672       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 4, 4, 32)     0           conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 4, 4, 256)    0           concatenate_105[0][0]            \n",
      "                                                                 dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 4, 4, 256)    1024        concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 4, 4, 256)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 4, 4, 128)    32768       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 4, 4, 32)     0           conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 4, 4, 288)    0           concatenate_106[0][0]            \n",
      "                                                                 dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 4, 4, 288)    1152        concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 4, 4, 288)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 4, 4, 128)    36864       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 4, 4, 32)     0           conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 4, 4, 320)    0           concatenate_107[0][0]            \n",
      "                                                                 dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 4, 4, 320)    1280        concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 4, 4, 320)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 4, 4, 128)    40960       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 4, 4, 32)     0           conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 4, 4, 352)    0           concatenate_108[0][0]            \n",
      "                                                                 dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 4, 4, 352)    1408        concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 4, 4, 352)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 4, 4, 128)    45056       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 4, 4, 32)     0           conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 4, 4, 384)    0           concatenate_109[0][0]            \n",
      "                                                                 dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 4, 4, 384)    1536        concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 4, 4, 384)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 4, 4, 128)    49152       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)           (None, 4, 4, 32)     0           conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 4, 4, 416)    0           concatenate_110[0][0]            \n",
      "                                                                 dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 4, 4, 416)    1664        concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 4, 4, 416)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 4, 4, 128)    53248       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 4, 4, 32)     0           conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 4, 4, 448)    0           concatenate_111[0][0]            \n",
      "                                                                 dropout_118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 4, 4, 448)    1792        concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 4, 4, 448)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 4, 4, 128)    57344       activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 4, 4, 32)     0           conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 4, 4, 480)    0           concatenate_112[0][0]            \n",
      "                                                                 dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 4, 4, 480)    1920        concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 4, 4, 480)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 4, 4, 128)    61440       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 4, 4, 32)     0           conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 4, 4, 512)    0           concatenate_113[0][0]            \n",
      "                                                                 dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 4, 4, 512)    2048        concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 4, 4, 512)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 4, 4, 128)    65536       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 4, 4, 32)     36864       conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 4, 4, 32)     0           conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 4, 4, 544)    0           concatenate_114[0][0]            \n",
      "                                                                 dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 4, 4, 544)    2176        concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 4, 4, 544)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 2, 2, 544)    0           activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2176)         0           average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           21770       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,474,602\n",
      "Trainable params: 4,436,394\n",
      "Non-trainable params: 38,208\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_res = dense_model(input_shape = (32,32,3), n_classes = 10)\n",
    "model_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370\n"
     ]
    }
   ],
   "source": [
    "print(len(model_res.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model_res.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss= history.history['loss']\n",
    "val_loss= history.history['val_loss']\n",
    "train_accuracy= history.history['accuracy']\n",
    "val_accuracy= history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12500/12500 [==============================] - 606s 48ms/step - loss: 0.3500 - accuracy: 0.8768 - val_loss: 0.4301 - val_accuracy: 0.8613\n",
      "Epoch 2/20\n",
      "12500/12500 [==============================] - 610s 49ms/step - loss: 0.3432 - accuracy: 0.8793 - val_loss: 0.4570 - val_accuracy: 0.8574\n",
      "Epoch 3/20\n",
      "12500/12500 [==============================] - 646s 52ms/step - loss: 0.3311 - accuracy: 0.8817 - val_loss: 0.4480 - val_accuracy: 0.8622\n",
      "Epoch 4/20\n",
      "12500/12500 [==============================] - 619s 50ms/step - loss: 0.3221 - accuracy: 0.8866 - val_loss: 0.4444 - val_accuracy: 0.8605\n",
      "Epoch 5/20\n",
      "12500/12500 [==============================] - 607s 49ms/step - loss: 0.3120 - accuracy: 0.8909 - val_loss: 0.4334 - val_accuracy: 0.8620\n",
      "Epoch 6/20\n",
      "12500/12500 [==============================] - 609s 49ms/step - loss: 0.3052 - accuracy: 0.8921 - val_loss: 0.4494 - val_accuracy: 0.8632\n",
      "Epoch 7/20\n",
      "12500/12500 [==============================] - 615s 49ms/step - loss: 0.2976 - accuracy: 0.8940 - val_loss: 0.4422 - val_accuracy: 0.8673\n",
      "Epoch 8/20\n",
      "12500/12500 [==============================] - 605s 48ms/step - loss: 0.2929 - accuracy: 0.8965 - val_loss: 0.4266 - val_accuracy: 0.8676\n",
      "Epoch 9/20\n",
      "12500/12500 [==============================] - 611s 49ms/step - loss: 0.2826 - accuracy: 0.9014 - val_loss: 0.4342 - val_accuracy: 0.8689\n",
      "Epoch 10/20\n",
      "12500/12500 [==============================] - 617s 49ms/step - loss: 0.2796 - accuracy: 0.9016 - val_loss: 0.4397 - val_accuracy: 0.8724\n",
      "Epoch 11/20\n",
      "12500/12500 [==============================] - 616s 49ms/step - loss: 0.2714 - accuracy: 0.9032 - val_loss: 0.4715 - val_accuracy: 0.8588\n",
      "Epoch 12/20\n",
      "12500/12500 [==============================] - 614s 49ms/step - loss: 0.2656 - accuracy: 0.9051 - val_loss: 0.4441 - val_accuracy: 0.8668\n",
      "Epoch 13/20\n",
      "12500/12500 [==============================] - 625s 50ms/step - loss: 0.2626 - accuracy: 0.9048 - val_loss: 0.4173 - val_accuracy: 0.8722\n",
      "Epoch 14/20\n",
      "12500/12500 [==============================] - 591s 47ms/step - loss: 0.2557 - accuracy: 0.9097 - val_loss: 0.4351 - val_accuracy: 0.8666\n",
      "Epoch 15/20\n",
      "12500/12500 [==============================] - 597s 48ms/step - loss: 0.2528 - accuracy: 0.9098 - val_loss: 0.4500 - val_accuracy: 0.8655\n",
      "Epoch 16/20\n",
      "12500/12500 [==============================] - 610s 49ms/step - loss: 0.2445 - accuracy: 0.9140 - val_loss: 0.4340 - val_accuracy: 0.8720\n",
      "Epoch 17/20\n",
      "12500/12500 [==============================] - 638s 51ms/step - loss: 0.2394 - accuracy: 0.9151 - val_loss: 0.4466 - val_accuracy: 0.8699\n",
      "Epoch 18/20\n",
      "12500/12500 [==============================] - 622s 50ms/step - loss: 0.2385 - accuracy: 0.9160 - val_loss: 0.4631 - val_accuracy: 0.8706\n",
      "Epoch 19/20\n",
      "12500/12500 [==============================] - 623s 50ms/step - loss: 0.2333 - accuracy: 0.9178 - val_loss: 0.4506 - val_accuracy: 0.8700\n",
      "Epoch 20/20\n",
      "12500/12500 [==============================] - 613s 49ms/step - loss: 0.2240 - accuracy: 0.9205 - val_loss: 0.4583 - val_accuracy: 0.8695\n"
     ]
    }
   ],
   "source": [
    "history = model_res.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    train_loss.append(history.history['loss'][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    val_loss.append(history.history['val_loss'][i])\n",
    "    train_accuracy.append(history.history['accuracy'][i])\n",
    "    val_accuracy.append(history.history['val_accuracy'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.249651551246643,\n",
       " 1.0645172595977783,\n",
       " 0.7750522494316101,\n",
       " 0.674221396446228,\n",
       " 0.7073315382003784,\n",
       " 0.6358838081359863,\n",
       " 0.5926175713539124,\n",
       " 0.5625372529029846,\n",
       " 0.5981152653694153,\n",
       " 0.5413559079170227,\n",
       " 0.5472973585128784,\n",
       " 0.5416108965873718,\n",
       " 0.504813015460968,\n",
       " 0.491455078125,\n",
       " 0.4809737205505371,\n",
       " 0.474918395280838,\n",
       " 0.4866385757923126,\n",
       " 0.4634874165058136,\n",
       " 0.48641133308410645,\n",
       " 0.4382675886154175,\n",
       " 0.43005985021591187,\n",
       " 0.45698824524879456,\n",
       " 0.44796234369277954,\n",
       " 0.44438374042510986]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4583 - accuracy: 0.8695\n",
      "Test loss: 0.4583326280117035\n",
      "Test accuracy: 0.8694999814033508\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model_res.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss_train = history.history['accuracy']\n",
    "# loss_val = history.history['val_accuracy']\n",
    "epochs = range(epochs)\n",
    "plt.plot(train_accuracy, 'g', label='Training accuracy')\n",
    "plt.plot(val_accuracy, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy of DENSENET-BC as in reseach paper\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss_train = history.history['accuracy']\n",
    "# loss_val = history.history['val_accuracy']\n",
    "# epochs = range(epochs)\n",
    "plt.plot(train_loss, 'g', label='Training loss')\n",
    "plt.plot(val_loss, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.title(\"loss of DENSENET-BC as in reseach paper\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save the trained weights in to .h5 format\n",
    "model_res.save_weights(\"DNST_res_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model_res, to_file='model_res.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cnn_cifr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
